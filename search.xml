<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Redis数据安全与性能保障]]></title>
      <url>%2Fpost%2Fredis-data-safety%2F</url>
      <content type="text"><![CDATA[持久化选项 复制 处理系统故障 redis事务 非事务型流水线 持久化选项 复制 处理系统故障 redis事务 非事务型流水线可以接受多个参数的添加命令和更新命令，比如：MGET,MSET,HMGET,HMSET,RPUSH,LPUSH,SADD,ZADD,这些命令简化了那些需要重复执行相同命令的操作，而极大的提升了性能 性能方面注意事项可以用性能测试程序redis-benchmark来测试（注：内容整理自《redis实战》）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis命令]]></title>
      <url>%2Fpost%2Fredis-command%2F</url>
      <content type="text"><![CDATA[字符串 列表 集合 散列 有序集合 字符串字符串可以存储：字节串（btye string），整数，浮点数自增自减命令INCR key-name 将键储存的值加上1 DECR key-name 将储存的值减去1 INCRBY key-name amount 将键储存的值加上整数amount DECRBY key-name amount 将键储存的值减去整数amount INCRBYFLOAT key-name amount 将键储存的值加上浮点数amount，这个命令在redis2.6或者以上的版本可用 redis还拥有对字符串其中一部分内容进行读取或者写入的操作 列表RPUSH key-name value[value...]–将一个或者多个值推入列表的右端，（LPUSH 是推入左端） RPOP key-name 移除并返回列表最右端的元素（LPOP 是左边） LINDEX key-name offset 返回列表中的偏移量为offset的元素 LRANGE key-name start end 返回列表从start偏移量到end偏移量范围内的所有元素 LTRIM key-name start end 对列表进行修剪，只保存从start到end范围的元素。start和end也会被保留 集合SADD SADD key-name item[item...] 将一个或多个元素添加到集合里面，并返回被添加元素当中原本并不存在与集合里面的元素数量 SREM key-name item[item...] 从集合里面移除一或多个元素，并返回被移除元素的数量 SISMEMBER SISMEMBER key-name item[item…]检查元素item是否存在于集合key-name里 SCARD SCARD key-name 返回集合包含的元素的数量 SMEMBERS SMEMBERkey-name 返回集合包含的所有元素 SRANDMEMBER SRANDMEMBER key-name[count]-从集合里面随机地返回一个或多个元素，当count为正数时，命令返回的元素不会重复，当为负数是，命令返回的元素可能会重复 SPOPSPOP key-name 随机地移除集合中的一个元素，并返回被移除的元素 SMOVE SMOVE source-key dest-key item 如果集合soucre-key包含元素item，那么从集合source-key里面移除元素item。并将元素item添加到集合dest-key中，如果item被成功移除，返回1.否则返回0 散列HMGET key-name key[key...] 从散列里面获取一个或对个键的值 HMSET key-name key value [key value..] 为散列里面的一个或多个键设置值 HDEL key-name key[key …]删除散列里面的一个或多个键值对，返回成功找到并删除键值对数量 HLEN key-name返回散列包含的键值对的数量 进阶：HEXISTS key-name key 检查给定键是否存在于散列中 HKEYS key-name获取散列包含的所有键 HVALS key-name获取散列包含的所有值 HGETALL key-name获取散列包含的所有键值对 HINCRBY key-name key increment 将键存储的值加上整数increment HINCRBYFLOAT key-name key increment 将键key存储的值加上浮点数increment 有序集合 发布和订阅SUBSCRIBEUNSUBSCRIBEPUBLISHPSUBSCRIBEPUNSUBSCRIBE 其他命令SORTMULTIEXECTTLEXPIRE （注：内容整理自《redis实战》）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Elasticsearch学习笔记]]></title>
      <url>%2Fpost%2Felasticsearch-study-note%2F</url>
      <content type="text"><![CDATA[Elasticsearch是一个可伸缩的开源全文搜索和分析引擎，它使你可以快速且接近实时的去保存，查询和分析海量的数据，他的潜在应用场景是作为一些有复杂搜索功能和需求的应用的搜索引擎 简介Elasticsearch是一个基于Apache Lucene(TM)的开源搜索引擎。无论在开源还是专有领域，Lucene可以被认为是迄今为止最先进、性能最好的、功能最全的搜索引擎库。但是，Lucene只是一个库。想要使用它，你必须使用Java来作为开发语言并将其直接集成到你的应用中，更糟糕的是，Lucene非常复杂，你需要深入了解检索的相关知识来理解它是如何工作的。Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。 与关系型数据库对比Relational DB -&gt; Databases -&gt; Tables -&gt; Rows -&gt; ColumnsElasticsearch -&gt; Indices -&gt; Types -&gt; Documents -&gt; Fields Elasticsearch集群可以包含多个索引(indices)（数据库），每一个索引可以包含多个类型(types)（表），每一个类型包含多个文档(documents)（行），然后每个文档包含多个字段(Fields)（列） 基础概念near realtime（NRT）es是一个接近实时的搜索平台，这意味着你查询一个文档的时候有一个延时。大约一秒 cluster集群是一个或多个节点（服务器）的集合在一起，保存所有的数据，联合所有节点一起提供查询能力。一个集群有一个唯一的名字，默认是“elasticsearch”,集群名很重要，因为集群节点加入集群的唯一方式是根据这个名字。 node节点的默认名字是漫威的一个角色，默认加入集群elasticsearch index索引是一系列具有相似特点文档的集合实际上，索引只是一个用来指向一个或多个分片(shards)的“逻辑命名空间(logical namespace) 「索引」含义的区分你可能已经注意到索引(index)这个词在Elasticsearch中有着不同的含义，所以有必要在此做一下区分:索引（名词） ：如上文所述，一个索引(index)就像是传统关系数据库中的数据库，它是相关文档存储的地方，index的复数是indices 或indexes。索引（动词） ：「索引一个文档」表示把一个文档存储到索引（名词）里，以便它可以被检索或者查询。这很像SQL中的INSERT关键字，差别是，如果文档已经存在，新的文档将覆盖旧的文档。 倒排索引 传统数据库为特定列增加一个索引，例如B-Tree索引来加速检索。Elasticsearch和Lucene使用一种叫做倒排索引(inverted index)的数据结构来达到相同目的。 Type索引中，类型是一种逻辑的分类，它的意义由使用者来赋予 mapping 每个类型(type)都有自己的映射(mapping)或者结构定义，就像传统数据库表中的列一样。所有类型下的文档被存储在同一个索引下，但是类型的映射(mapping)会告诉Elasticsearch不同的文档如何被索引Elasticsearch支持以下简单字段类型：类型 表示的数据类型String stringWhole number byte, short, integer, longFloating point float, doubleBoolean booleanDate date document文档是搜索信息的基本单元，用json表达，文档必须被包含于一个type中 文档 ID文档唯一标识由四个元数据字段组成： _id：文档的字符串 ID _type：文档的类型名 _index：文档所在的索引 _uid：_type 和 _id 连接成的 type#id 默认情况下，_uid 是被保存（可取回）和索引（可搜索）的。_type 字段被索引但是没有保存，_id 和_index 字段则既没有索引也没有储存，它们并不是真实存在的。 shards&amp;replicases提供能力，让你把index分成好几个部分，叫做分片，当你创建索引的时候，你可以简单的定义分片的个数，每个分片本身是一个独立的功能齐全的“索引”，可以被放到任何的集群节点中 分片的意义：1.可以水平分割和扩展数据2.可以把操作分配给多个分区，提高性能 es允许你制作一个或多个分片的副本。叫做复制分片复制分片的意义：1、他提供了高可用性，副本和原始分区不处于一个节点中。2.他提高了性能，因为搜索可以在任何分区上允许。每一个分片是一个lucene索引，每个Lucene实例有一个最大的存放文档的数量。这个数量是2417483519 analysis分析也称分词Elasticsearch中的数据可以大致分为两种类型：确切值 及 全文文本。确切值是确定的，正如它的名字一样。比如一个date或用户ID，也可以包含更多的字符串比如username或email地址。全文文本常常被称为非结构化数据，而对于全文数据的查询来说，却有些微妙。我们不会去询问这篇文档是否匹配查询要求？。 但是，我们会询问这篇文档和查询的匹配程度如何？。换句话说，对于查询条件，这篇文档的相关性有多高？ 为了方便在全文文本字段中进行这些类型的查询，Elasticsearch首先对文本分析(analyzes)，然后使用结果建立一个倒排索引。 分析(analysis)机制用于进行全文文本(Full Text)的分词，以建立供搜索用的反向索引。 分析(analysis)是这样一个过程：首先，标记化一个文本块为适用于倒排索引单独的词(term)然后标准化这些词为标准形式，提高它们的“可搜索性”或“查全率” 这个工作是分析器(analyzer)完成的。一个分析器(analyzer)只是一个包装用于将三个功能放到一个包里：字符过滤器1.首先字符串经过字符过滤器(character filter)，它们的工作是在标记化前处理字符串。字符过滤器能够去除HTML标记，或者转换”&amp;”为”and”。分词器2.下一步，分词器(tokenizer)被标记化成独立的词。一个简单的分词器(tokenizer)可以根据空格或逗号将单词分开（译者注：这个在中文中不适用）标记过滤3.最后，每个词都通过所有标记过滤(token filters)，它可以修改词（例如将”Quick”转为小写），去掉词（例如停用词像”a”、”and”、”the”等等），或者增加词（例如同义词像”jump”和”leap”） index参数控制字符串以何种方式被索引。它包含以下三个值当中的一个：analyzed首先分析这个字符串，然后索引。换言之，以全文形式索引此字段。not_analyzed索引这个字段，使之可以被搜索，但是索引内容和指定值一样。不分析此字段。no不索引这个字段。这个字段不能为搜索到。string类型字段默认值是analyzed。如果我们想映射字段为确切值，我们需要设置它为not_analyzed：{ “tag”: { “type”: “string”, “index”: “not_analyzed” }}其他简单类型（long、double、date等等）也接受index参数，但相应的值只能是no和not_analyzed，它们的值不能被分析。 Elasticsearch提供很多开箱即用的字符过滤器，分词器和标记过滤器。这些可以组合来创建自定义的分析器以应对不同的需求。 string类型的字段，默认的，考虑到包含全文本，它们的值在索引前要经过分析器分析，并且在全文搜索此字段前要把查询语句做分析处理。对于string字段，两个最重要的映射参数是index和analyer。 highlight很多应用喜欢从每个搜索结果中高亮(highlight)匹配到的关键字，这样用户可以知道为什么这些文档和查询相匹配。 score每个节点都有一个_score字段，这是相关性得分(relevance score)，它衡量了文档与查询的匹配程度。默认的，返回的结果中关联性最大的文档排在首位；这意味着，它是按照_score降序排列的。这种情况下，我们没有指定任何查询，所以所有文档的相关性是一样的，因此所有结果的_score都是取得一个中间值1max_score指的是所有文档匹配查询中_score的最大值。 refresh默认情况下，每个分片每秒自动刷新一次。这就是为什么说Elasticsearch是近实时的搜索了：文档的改动不会立即被搜索，但是会在一秒内可见。 sort排序默认情况下，结果集会按照相关性进行排序 – 相关性越高，排名越靠前字段值排序:按时间排序 GET /_search { &quot;query&quot; : { &quot;filtered&quot; : { &quot;filter&quot; : { &quot;term&quot; : { &quot;user_id&quot; : 1 }} } }, &quot;sort&quot;: { &quot;date&quot;: { &quot;order&quot;: &quot;desc&quot; }} } 返回： &quot;hits&quot; : { &quot;total&quot; : 6, &quot;max_score&quot; : null, &lt;1&gt; &quot;hits&quot; : [ { &quot;_index&quot; : &quot;us&quot;, &quot;_type&quot; : &quot;tweet&quot;, &quot;_id&quot; : &quot;14&quot;, &quot;_score&quot; : null, &lt;1&gt; &quot;_source&quot; : { &quot;date&quot;: &quot;2014-09-24&quot;, ... }, &quot;sort&quot; : [ 1411516800000 ] &lt;2&gt; }, ... } _score 是比较消耗性能的, 而且通常主要用作排序 – 我们不是用相关性进行排序的时候，就不需要统计其相关性字段值默认以顺序排列（从小到大 ），而 _score 默认以倒序排列。 缓存过滤器是怎么计算的。它们的核心是一个字节集来表示哪些文档符合这个过滤器。Elasticsearch 主动缓存了这些字节集留作以后使用。一旦缓存后，当遇到相同的过滤时，这些字节集就可以被重用，而不需要重新运算整个过滤。集很“聪明”：他们会增量更新。你索引中添加了新的文档，只有这些新文档需要被添加到已存的字节集中，而不是一遍遍重新计算整个缓存的过滤器。过滤器和整个系统的其他部分一样是实时的，你不需要关心缓存的过期时间。 安装 首先需要依赖java7以上版本 curl -L -O https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.3.3/elasticsearch-2.3.3.tar.gztar -xvf elasticsearch-2.3.3.tar.gzcd elasticsearch-2.3.3/bin./elasticsearch 可以在启动的时候重写集群和节点的名字./elasticsearch –cluster.name my_cluster_name –node.name my_node_name 默认，es使用9200端口提供 restapi访问 安装配置：config/elasticsearch.yml network : host : 10.0.0.4 path: logs: /var/log/elasticsearch data: /var/data/elasticsearch cluster: name: &lt;NAME OF YOUR CLUSTER&gt; node: name: &lt;NAME OF YOUR NODE&gt; 浏览你的集群es提供了丰富的restapi用于和集群直接通信包括：1.检查集群，节点，索引，状态和统计2.管理集群，节点，索引数据和与元数据3.对索引curd4.使用高级搜索功能，比如分页，排序，过滤，脚本，聚合和其他很多 集群健康：curl &apos;localhost:9200/_cat/health?v&apos; 返回epoch timestamp cluster status node.total node.data shards pri relo init unassign1394735289 14:28:09 elasticsearch green 1 1 0 0 0 0 0 颜色 意义green 所有主要分片和复制分片都可用yellow 所有主要分片可用，但不是所有复制分片都可用red 不是所有的主要分片都可用 列举出所有索引：curl&apos;localhost:9200/_cat/indices?v&apos; 创建一个索引：curl -XPUT &apos;localhost:9200/customer?pretty&apos; 创建一个文档：curl -XPUT &apos;localhost:9200/customer/external/1?pretty&apos;-d &apos;{ &quot;name&quot;: &quot;John Doe&quot;}&apos; 删除一个索引：curl -XDELETE &apos;localhost:9200/customer?pretty&apos; 修改你的数据替代你的文档： curl -XPUT ‘localhost:9200/customer/external/1?pretty’-d ‘ { “name”: “John Doe” }’ curl -XPUT &apos;localhost:9200/customer/external/1?pretty&apos;-d &apos; { &quot;name&quot;: &quot;Jane Doe&quot; }&apos; 如果指定了id，去创建，之前的那个会被覆盖如果没有指定id，es会随机的生成一个id 更新文档：es并不会真正的更新文档，当我们进行更新操作的时候，es删除原来的文档，然后添加一个新的文档。 更新文档也可以使用脚本，动态脚本在1.4.3版本默认被禁用curl -XPOST ‘localhost:9200/customer/external/1/_update?pretty’-d ‘{ “script” : “ctx._source.age += 5” }’ ctx._source指向要被修改的文档 es后续将会提供能力，类似sql中的 UPDATE-WHERE statement 删除文档curl -XDELETE &apos;localhost:9200/customer/external/2?pretty&apos; delete-by-query 插件可以删除满足要求的一类文档 批量操作：curl -XPOST &apos;localhost:9200/customer/external/_bulk?pretty&apos; -d &apos; {&quot;index&quot;:{&quot;_id&quot;:&quot;1&quot;}} {&quot;name&quot;: &quot;John Doe&quot; } {&quot;index&quot;:{&quot;_id&quot;:&quot;2&quot;}} {&quot;name&quot;: &quot;Jane Doe&quot; } &apos; curl -XPOST &apos;localhost:9200/customer/external/_bulk?pretty&apos; -d &apos; {&quot;update&quot;:{&quot;_id&quot;:&quot;1&quot;}} {&quot;doc&quot;: { &quot;name&quot;: &quot;John Doe becomes Jane Doe&quot; } } {&quot;delete&quot;:{&quot;_id&quot;:&quot;2&quot;}} &apos; 浏览你的数据查询APItook: es搜索使用了多少毫秒timed_out 是否超时_shards 告诉我们多少个分片被搜索，和被成功和失败搜索的分片的数量hits 搜索结果hits.total 结果数量hits.hits 搜索结果的列表（默认给出前10个）_score 评分 查询语句：Query DSL {&quot;query&quot;:{&quot;match_all&quot;:{}}} 规定数目curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos;-d &apos; { &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;size&quot;: 1 }&apos; 分页curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos;-d &apos; { &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;from&quot;: 10, &quot;size&quot;: 10 }&apos; 规定返回指定的fieldcurl -XPOST &apos;localhost:9200/bank/_search?pretty&apos;-d &apos; { &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;_source&quot;: [&quot;account_number&quot;, &quot;balance&quot;] }&apos; match:curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos;-d &apos; { &quot;query&quot;: { &quot;match&quot;: { &quot;account_number&quot;: 20 } } }&apos; bool: 加入布尔逻辑 curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos;-d &apos; { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;match&quot;: { &quot;address&quot;: &quot;mill&quot; } }, { &quot;match&quot;: { &quot;address&quot;: &quot;lane&quot; } } ] } } }&apos; curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos;-d &apos; { &quot;query&quot;: { &quot;bool&quot;: { &quot;should&quot;: [ { &quot;match&quot;: { &quot;address&quot;: &quot;mill&quot; } }, { &quot;match&quot;: { &quot;address&quot;: &quot;lane&quot; } } ] } } }&apos; curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos;-d &apos; { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;match&quot;: { &quot;age&quot;: &quot;40&quot; } } ], &quot;must_not&quot;: [ { &quot;match&quot;: { &quot;state&quot;: &quot;ID&quot; } } ] } } }&apos; filter使用filter，es不再计算相关性得分，只是严格的按照条件过滤比如：range curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos;-d &apos; { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: { &quot;match_all&quot;: {} }, &quot;filter&quot;: { &quot;range&quot;: { &quot;balance&quot;: { &quot;gte&quot;: 20000, &quot;lte&quot;: 30000 } } } } } }&apos; Aggregations提供能力是分组和提炼你的数据 就像sql里面的GROUP BYes里你可以查询返回hit和hit的聚合，在一次查询中而且可以进行多重聚合 安装state分类，然后返回10个状态，按照数量排序设置size=0，不展示hits，因为我们只关心聚合结果 SELECT state, COUNT(*) FROM bank GROUP BY state ORDER BY COUNT(*) DESC 平局值 聚合每一种balance的平均值 suggestlasticsearch 0.9.0.3终于基于AnalyzingSuggester加上了prefix suggestions ，可直接做搜索提示功能，在0.9.0.1之前版本都是使用外部插件实现的参考文章http://www.nosqldb.cn/1376024289369.htmlhttp://www.cnblogs.com/jiuyuehe/p/3840821.html 总结es是一个简单又复杂的产品，还有很多高级的功能。 拓展官方文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html elasticSearch中文社区：http://elasticsearch.cn/ elasticsearch 索引优化:http://itindex.net/detail/52316-elasticsearch-%E7%B4%A2%E5%BC%95-%E4%BC%98%E5%8C%96 与其他相似功能产品对比：http://www.cnblogs.com/chowmin/articles/4629220.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Elasticsearch自动补齐建议-completion suggester]]></title>
      <url>%2Fpost%2Felasticsearch-completion-suggester%2F</url>
      <content type="text"><![CDATA[mapping 添加测试数据 DSL 结果 代码 1.mappingcurl -XPUT 192.168.0.1:9200/person -d&apos; //新建一个persion的索引 { &quot;mappings&quot;: { &quot;person&quot;: { //这个是_type &quot;properties&quot;: { &quot;name&quot;: { &quot;type&quot;: &quot;string&quot; } &quot;tag_suggest&quot;: { &quot;type&quot;: &quot;completion&quot;, //设置为completion才能被suggest捕获 &quot;index_analyzer&quot;: &quot;ik&quot;, &quot;search_analyzer&quot;: &quot;ik&quot;, &quot;payloads&quot;: false } } } } }&apos; 2 .添加测试数据curl -XPUT 192.168.2.20:9200/person/person/1 -d&apos; { &quot;name&quot;: [ &quot;david&quot;, &quot;jacky&quot; ], &quot;tag_suggest&quot;: { &quot;input&quot;: [ &quot;david&quot;, &quot;jacky&quot; ] } }&apos; curl -XPUT 192.168.0.1:9200/person/person/1 -d&apos; { &quot;name&quot;: [ &quot;andy&quot;, &quot;jackson&quot; ], &quot;tag_suggest&quot;: { &quot;input&quot;: [ &quot;andy&quot;, &quot;jackson&quot; ] } }&apos; 3.DSLcurl -XPOST 192.168.0.1:9200/person/_suggest -d&apos; { &quot;person_suggest&quot;:{ &quot;text&quot;:&quot;jack&quot;, &quot;completion&quot;: { &quot;field&quot; : &quot;tag_suggest&quot; } } }&apos; 4.结果{ &quot;_shards&quot;: { &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;failed&quot;: 0 }, &quot;person_suggest&quot;: [ { &quot;text&quot;: &quot;word&quot;, &quot;offset&quot;: 0, &quot;length&quot;: 4, &quot;options&quot;: [ { &quot;text&quot;: &quot;jacky&quot;, &quot;score&quot;: 1 }, { &quot;text&quot;: &quot;jackson&quot;, &quot;score&quot;: 1 } ] } ] } 5.代码123456789101112131415161718192021 CompletionSuggestionBuilder completionSuggestionBuilder = new CompletionSuggestionBuilder("complete"); completionSuggestionBuilder.text(paramMap.get("text")); completionSuggestionBuilder.field(paramMap.get("field")); completionSuggestionBuilder.size(10); IElasticsearchClient client = index.getIndexClient(); CompletionSuggestionBuilder completionSuggestion = completionSuggestionBuilder SuggestResponse resp = client.prepareSuggest(realIndexName) .addSuggestion(completionSuggestion).execute().actionGet(); List&lt;? extends Suggest.Suggestion.Entry&lt;? extends Suggest.Suggestion.Entry.Option&gt;&gt; list = response.getSuggest().getSuggestion("complete").getEntries(); List&lt;String&gt; suggestList = new ArrayList&lt;String&gt;(); if (list == null) &#123; return null; &#125; else &#123; for (Suggest.Suggestion.Entry&lt;? extends Suggest.Suggestion.Entry.Option&gt; e : list)&#123; for (Suggest.Suggestion.Entry.Option option : e) &#123; suggestList.add(option.getText().toString()); &#125; &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Elasticsearch地理位置查询-Geo Distance Range Query]]></title>
      <url>%2Fpost%2Felasticsearch-geo-distance-query%2F</url>
      <content type="text"><![CDATA[官方文档：https://www.elastic.co/guide/en/elasticsearch/reference/2.4/query-dsl-geo-distance-query.html#_geohash_3 索引mapping定义:索引中定义一个字段pin，添加一个属性location，type为geo_point &quot;pin&quot; : { &quot;properties&quot; : { &quot;location&quot; : { &quot;type&quot; : &quot;geo_point&quot; } } } DSL:报文中的包含一个match all的query , filter中的distance指定了距离范围，pin.location是经纬度 { &quot;bool&quot; : { &quot;must&quot; : { &quot;match_all&quot; : {} }, &quot;filter&quot; : { &quot;geo_distance&quot; : { &quot;distance&quot; : &quot;200km&quot;, &quot;pin.location&quot; : { &quot;lat&quot; : 40, &quot;lon&quot; : -70 } } } } } 代码：拼装 query 和 sort1234567891011121314QueryBuilder builder = new GeoDistanceRangeQueryBuilder （"pin.location"） .point(lat,lon) .from("0km") .to("10000km") .includeLower(true) .includeUpper(false) .optimizeBbox("memory") .geoDistance(GeoDistance.ARC); GeoDistanceSortBuilder sort = SortBuilders.geoDistanceSort("location"); GeoDistanceSortBuilder sort = new GeoDistanceSortBuilder("location"); sort.unit(DistanceUnit.KILOMETERS); sort.order(SortOrder.ASC); sort.point(lat,lon); 构造dsl生产器12345 SearchSourceBuilder sourceBuilder = SearchSourceBuilder.searchSource(); sourceBuilder.query(QueryBuilders.boolQuery()) .must(builder) sourceBuilder.sort(sort); 调用elasticsearch123456789101112131415final SearchResponse response = executeGet(new ClientCallback&lt;SearchResponse&gt;() &#123; @Override public ActionFuture&lt;SearchResponse&gt; execute(final Client client) &#123; final SearchSourceBuilder sourceBuilder = SearchParamUtils .genSearchSourceBuilderFromSearchParam(searchParam); String[] indexNames = new String[aliasIndexNameList.size()]; SearchRequest request = Requests.searchRequest(aliasIndexNameList.toArray(indexNames)) .types(type); request.source(sourceBuilder.toString()); if (searchParam.getSearchType() != null) &#123; request.searchType(searchParam.getSearchType()); &#125; return client.search(request); &#125; &#125;); 获取每条记录的距离12345678910SearchResult searchResult = new SearchResult(); SearchHits hits = response.getHits(); for (SearchHit hit : hits.getHits()) &#123; Object[] sortArray = hit.getSortValues(); if(sortArray!=null&amp;&amp;sortArray.length&gt;0)&#123; BigDecimal geoDis = new BigDecimal((Double) sortArray[sortArray.length-1]); map.put("geoDistance", geoDis.setScale(0, BigDecimal.ROUND_HALF_DOWN)); System.out.println("距离" + hit.getSource().get("geoDistance")); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Elasticsearch如何评分?-Apache Lucene默认评分公式解释]]></title>
      <url>%2Fpost%2Flucene-score-rule%2F</url>
      <content type="text"><![CDATA[elasticsearch使用了lucene的评分功能,lucene默认评分机制：TF/IDF(词频/逆文档频率)算法 lucene默认评分机制：TF/IDF(词频/逆文档频率)算法默认评分公式解释何时文档被匹配上当一个文档经过lucene返回，则意味着该文档与用户提交的查询时匹配的，在这种情况下，每个返回的文档都会有一个得分，得分越高，文档相关度更高，但是，同一个文档针对不同查询的得分是不同的，比较某个文档在不同查询中的分数是没有意义的，这是因为文档得分依赖多个因子，除了权重和查询本身的结构，还包括匹配的词项的数目，词项所在字段，以及用于查询规范化的匹配类型等。 计算文档得分需要考虑以下因子 文档权重（document boost）：索引期赋予某个文档的权重值 字段权重（field boost）:查询期赋予某个字段的权重值 协调因子（coord）：基于文档中词项命中个数的协调因子，一个文档中命中了查询中的词项越多，得分越高(比如：查询关键词被分词为A和B,如果文档1命中了A和B,文档2命中了A,那么在这个项目上，文档1的分数更高) 逆文档频率(inverse document frequency):一个基于词项的因子,用来告诉评分公式该词项有多么罕见，逆文档频率越低，词项越罕见，评分公式利用该因子为包含罕见词项的文档加权(比如：查询关键词是A和B,如果文档1命中了A,文档2命中了B,但是在整个文档范围内，A出现的次数比B少，那么在这个项目中，文档1分数更高) 长度范数(length norm):每个字段的基于词项个数的归一化因子，一个字段包含的词项越多，改因子的权重越低，*这意味着lucene评分公式更”喜欢”包含更少词项的字段(比如：查询关键词是A,文档1和2都匹配上了A,但是文档1内容长度比文档1短，那么在这个项目中，文档1分数更高) 词频：一个基于词项的因子，用来表示一个词项在某个文档中出现多少次，词频越高，文档得分越高(比如：查询关键词是A，文档1和文档1都匹配上了，但是文档1中出现了2次A,文档2中出现了1次A,那么在这个项目中，文档1分数更高) 查询范数（query norm）：一个基于查询的归一化因子，它等于查询中词项的权重平方和，查询范数使得不同查询的得分能相互比较，尽管这种比较通常是困难且不可行的 TF/IDF评分公式Lucene理论评分公式注意，你并不需要深入理解这个公式的来龙去脉，了解它的工作原理非常重要上面的公式理论形式糅合了布尔检索模型和向量空间检索模型，我们可以不讨论这个理论评分公式，直接跳到lucene实际评分公式 Lucene实际评分公式现在让我来看看Lucene实际评分公式： 解释：这是一个关于查询q和文档d的函数，有两个因子coord和queryNorm并不直接依赖查询词项，而是与查询词项的一个求和公式相乘，求和公式中的每个加数由以下因子连乘所得：词频 逆文档频率 词项权重 长度范数 由这个公式我们可以导出一些规则： 越多罕见的词项被匹配上，文档分数越高 文档字段越短，文档分数越高 权重越高（无论是索引期还查询期赋予的权重值），文档得分越高 elasticsearch如何看评分elasticsearch使用了lucene的评分功能，但是好在我们可以替换默认的评分算法，elasticsearch使用了Lucene的评分功能但是不仅限于lucene的评分功能，用户可以使用各种不同的查询类型以精确控制文档的评分计算，如custom_boost_factor查询、constant_score查询，custom_score查询）还可以通过使用脚本（scrpting）来改变文档得分，还可以使用二次评分功能，通过在返回文档集合之上执行另外一个查询，重新计算前N个文档得分 （注：内容整理自《深入理解elasticsearch》，斜体为本人添加的理解）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java IO 简介]]></title>
      <url>%2Fpost%2Fjava-io-introduction%2F</url>
      <content type="text"><![CDATA[学习Java中的IO，首先要理解Java中IO的流模型。所谓流，可以假想成河流，流的数据源，就是河流的发源地，流是单向的，流的单向性，就像河流的水流是单向的一样。 Java中的流可以从两方面的分类 输入流和输出流 节点流和处理流 输入流和输出流，就是程序和外部的数据源进行IO操作。这些数据源可以是可以是内存，文件，还可以是网络上的一个URL。 输入流和输出流的定义都是相对程序来说的，也就是输入流是从外部读取数据进入程序，然后由程序处理。输出流是从程序中输出的数据。 节点流和处理流。节点流是直接跟数据源连接的流，而处理流是用来装饰节点流的，是为使节点流有更多的功能。 io流 输入流 输出流 字节流 InputStream OutputStream 字符流 Reader Writer 对于上面的字节流和字符流，他们的区别就在于字节流会以字节的形式来处理数据，而字符流会以字符的形式来处理数据。 对于字节流的输入流，就是 InputStream的抽象类向下延伸。因为数据源可以在在文件中，在内存中。所以，一般的字节输入流有 FileInputStream、ByteArrayInputStream 等方法。因此，对应的，就有字节输出流的 FileOutputStream、ByteArrayOutputStream。 而对于字符流的输入流，就是 Reader的抽象类的向下延伸。同样的，数据源可以在文件中，在内存中。因此，一般的字符输入流有 FileReader、CharArrayReader等方法。输出流也相对应。 上面了解了节点流。下面是处理流。 所谓处理流，就是不直接连接到数据源，而是对连接数据流的节点流进行装饰，使得流能提供更多更好的功能。 常见的处理流有 缓冲流。BufferedReader、BufferedWriter、BufferedInputStream、BufferedOutputStream。这种流是就是为增加了缓冲功能，提高的IO效率。 字节流转为字符流。 InputStreamReader，InputStreamWriter，当然，可以在创建此类的时候设置字符编码。 对象序列化流。ObjectInputStream、ObjectOutputStream。 各种类型数据的输入输出。DataInputStream、DataOutputStream。 行流。LineNumberReader；LineNumberInputStream 打印流。PrintWriter；PrintOutputStream。 再次理解一下流的概念流是一组有顺序的，有起点和终点的字节集合，是对数据传输的总称或抽象。即数据在两设备间的传输称为流，流的本质是数据传输，根据数据传输特性将流抽象为各种类，方便更直观的进行数据操作。 字符流和字节流字符流的由来： 因为数据编码的不同，而有了对字符进行高效操作的流对象。本质其实就是基于字节流读取时，去查了指定的码表。 字节流和字符流的区别： 读写单位不同：字节流以字节（8bit）为单位，字符流以字符为单位，根据码表映射字符，一次可能读多个字节。 处理对象不同：字节流能处理所有类型的数据（如图片、avi等），而字符流只能处理字符类型的数据。 结论：只要是处理纯文本数据，就优先考虑使用字符流。 除此之外都使用字节流。 输入流和输出流对输入流只能进行读操作，对输出流只能进行写操作，程序中需要根据待传输数据的不同特性而使用不同的流。 Java IO流对象 输入字节流InputStreamIO 中输入字节流的继承图可见下图，可以看出： InputStream 是所有的输入字节流的父类，它是一个抽象类。 ByteArrayInputStream、StringBufferInputStream、FileInputStream 是三种基本的介质流，它们分别从Byte 数组、StringBuffer、和本地文件中读取数据。PipedInputStream 是从与其它线程共用的管道中读取数据，与Piped 相关的知识后续单独介绍。 ObjectInputStream 和所有FilterInputStream 的子类都是装饰流（装饰器模式的主角）。 输入字节流InputStreamIO 中输入字节流的继承图可见下图，可以看出： OutputStream 是所有的输出字节流的父类，它是一个抽象类。 ByteArrayOutputStream、FileOutputStream 是两种基本的介质流，它们分别向Byte 数组、和本地文件中写入数据。PipedOutputStream 是向与其它线程共用的管道中写入数据， ObjectOutputStream 和所有FilterOutputStream 的子类都是装饰流。 字节流的输入与输出的对应 图中蓝色的为主要的对应部分，红色的部分就是不对应部分。紫色的虚线部分代表这些流一般要搭配使用。从上面的图中可以看出Java IO 中的字节流是极其对称的。“存在及合理”我们看看这些字节流中不太对称的几个类吧！ LineNumberInputStream 主要完成从流中读取数据时，会得到相应的行号，至于什么时候分行、在哪里分行是由改类主动确定的，并不是在原始中有这样一个行号。在输出部分没有对应的部分，我们完全可以自己建立一个LineNumberOutputStream，在最初写入时会有一个基准的行号，以后每次遇到换行时会在下一行添加一个行号，看起来也是可以的。好像更不入流了。 PushbackInputStream 的功能是查看最后一个字节，不满意就放入缓冲区。主要用在编译器的语法、词法分析部分。输出部分的BufferedOutputStream 几乎实现相近的功能。 StringBufferInputStream 已经被Deprecated，本身就不应该出现在InputStream 部分，主要因为String 应该属于字符流的范围。已经被废弃了，当然输出部分也没有必要需要它了！还允许它存在只是为了保持版本的向下兼容而已。 SequenceInputStream 可以认为是一个工具类，将两个或者多个输入流当成一个输入流依次读取。完全可以从IO 包中去除，还完全不影响IO 包的结构，却让其更“纯洁”――纯洁的Decorator 模式。 PrintStream 也可以认为是一个辅助工具。主要可以向其他输出流，或者FileInputStream 写入数据，本身内部实现还是带缓冲的。本质上是对其它流的综合运用的一个工具而已。一样可以踢出IO 包！System.out 和System.out 就是PrintStream 的实例！ 字符输入流Reader在上面的继承关系图中可以看出： Reader 是所有的输入字符流的父类，它是一个抽象类。 CharReader、StringReader 是两种基本的介质流，它们分别将Char 数组、String中读取数据。PipedReader 是从与其它线程共用的管道中读取数据。 BufferedReader 很明显就是一个装饰器，它和其子类负责装饰其它Reader 对象。 FilterReader 是所有自定义具体装饰流的父类，其子类PushbackReader 对Reader 对象进行装饰，会增加一个行号。 InputStreamReader 是一个连接字节流和字符流的桥梁，它将字节流转变为字符流。FileReader 可以说是一个达到此功能、常用的工具类，在其源代码中明显使用了将FileInputStream 转变为Reader 的方法。我们可以从这个类中得到一定的技巧。Reader 中各个类的用途和使用方法基本和InputStream 中的类使用一致。后面会有Reader 与InputStream 的对应关系。 字符输出流Writer在上面的关系图中可以看出： Writer 是所有的输出字符流的父类，它是一个抽象类。 CharArrayWriter、StringWriter 是两种基本的介质流，它们分别向Char 数组、String 中写入数据。PipedWriter 是向与其它线程共用的管道中写入数据， BufferedWriter 是一个装饰器为Writer 提供缓冲功能。 PrintWriter 和PrintStream 极其类似，功能和使用也非常相似。 OutputStreamWriter 是OutputStream 到Writer 转换的桥梁，它的子类FileWriter 其实就是一个实现此功能的具体类（具体可以研究一SourceCode）。功能和使用和OutputStream 极其类似，后面会有它们的对应图。 字符流的输入与输出的对应 字符流与字节流转换转换流的特点： 其是字符流和字节流之间的桥梁 可对读取到的字节数据经过指定编码转换成字符 可对读取到的字符数据经过指定编码转换成字节 何时使用转换流？ 当字节和字符之间有转换动作时； 流操作的数据需要编码或解码时。 具体的对象体现： InputStreamReader:字节到字符的桥梁 OutputStreamWriter:字符到字节的桥梁 这两个流对象是字符体系中的成员，它们有转换作用，本身又是字符流，所以在构造的时候需要传入字节流对象进来。 File类File类是对文件系统中文件以及文件夹进行封装的对象，可以通过对象的思想来操作文件和文件夹。 File类保存文件或目录的各种元数据信息，包括文件名、文件长度、最后修改时间、是否可读、获取当前文件的路径名，判断指定文件是否存在、获得当前目录中的文件列表，创建、删除文件和目录等方法。 RandomAccessFile类该对象并不是流体系中的一员，其封装了字节流，同时还封装了一个缓冲区（字符数组），通过内部的指针来操作字符数组中的数据。 该对象特点： 该对象只能操作文件，所以构造函数接收两种类型的参数：a.字符串文件路径；b.File对象。 该对象既可以对文件进行读操作，也能进行写操作，在进行对象实例化时可指定操作模式(r,rw) 注意：该对象在实例化时，如果要操作的文件不存在，会自动创建；如果文件存在，写数据未指定位置，会从头开始写，即覆盖原有的内容。 可以用于多线程下载或多个线程同时写数据到文件。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mybatis使用where标签时遇到的一个问题与trim标签的使用]]></title>
      <url>%2Fpost%2Fmybatis-where-trim%2F</url>
      <content type="text"><![CDATA[今天遇到一个场景需要写一个这样的查询语句：用户对象userInfo包含下面几个字段：userName phone email qqId weiboId wxId 现在新注册用户，传过来一个注册userInfo对象，现在要到数据库中验证状态status=1 （表示激活的用户）的用户中，是否存在一个用户，只要它这些字段中至少有一个与新注册的对象对应的字段内容相同，那就说明重复注册。 翻译成sql语句表示一下的意思大概就是：select * from tablename where(userName=”xxx”or phone =”xxx”or …)and status=1 一开始我是这样写的，在mybatis中的代码就是这样：1234567891011121314151617181920212223242526&lt;select id="selectBySelective" resultType="xxx.UserInfo"&gt; select &lt;include refid="Base_Column_List" /&gt; from uc_user &lt;where&gt; (&lt;if test="userName != null" &gt; user_name = #&#123;userName&#125; &lt;/if&gt; &lt;if test="email != null" &gt; or email = #&#123;email&#125; &lt;/if&gt; &lt;if test="phone != null" &gt; or phone = #&#123;phone&#125; &lt;/if&gt; &lt;if test="weiboId != null" &gt; or weibo_id = #&#123;weiboId&#125; &lt;/if&gt; &lt;if test="wxId != null" &gt; or wx_id = #&#123;wxId&#125; &lt;/if&gt; &lt;if test="qqId != null" &gt; or qq_id = #&#123;qqId&#125; &lt;/if&gt;) &lt;/where&gt; and status = 1&lt;/select&gt; 这样代码看似没有什么问题但是其实是有问题的。为什么呢？如果userName 为空，后面某字段不为空，最后的sql语言会成为这样：1select * from uc_user where(or email = "xxx") and status = 1 使用mybatis &lt; where &gt; 标签就是为了防止这种情况，mybatis会在第一个userName 为空的情况下，帮我们去掉后面的语句的第一个”or” 但是我加了where标签中加入（）后，语句会报错。因为自动去掉”or”会失效。 查看了mybatis官方文档发现了另一个标签 &lt; trim &gt;可以通过自定义 trim 元素来定制我们想要的功能 trim标签包围的内容可以设置几个属性：prefix ：内容之前加的前缀suffix ：内容之后加的后缀prefixOverrides： 属性会忽略通过管道分隔的文本序列（注意此例中的空格也是必要的，多个忽略序列用“|”隔开）。它带来的结果就是所有在 prefixOverrides 属性中指定的内容将被移除。 所以我修改后的代码是：1234567891011121314151617181920212223242526&lt;select id="selectBySelective" resultType="xxx.UserInfo"&gt; select &lt;include refid="Base_Column_List" /&gt; from uc_user &lt;trim prefix="WHERE (" suffix=")" prefixOverrides="AND |OR "&gt; &lt;if test="userName != null" &gt; user_name = #&#123;userName&#125; &lt;/if&gt; &lt;if test="email != null" &gt; or email = #&#123;email&#125; &lt;/if&gt; &lt;if test="phone != null" &gt; or phone = #&#123;phone&#125; &lt;/if&gt; &lt;if test="weiboId != null" &gt; or weibo_id = #&#123;weiboId&#125; &lt;/if&gt; &lt;if test="wxId != null" &gt; or wx_id = #&#123;wxId&#125; &lt;/if&gt; &lt;if test="qqId != null" &gt; or qq_id = #&#123;qqId&#125; &lt;/if&gt; &lt;/trim&gt; and status = 1&lt;/select&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java多线程简介之休眠、优先级、让步、后台线程、加入一个线程、异常捕获、共享受限资源]]></title>
      <url>%2Fpost%2Fthinking-in-java-readnote-concurrent-02%2F</url>
      <content type="text"><![CDATA[休眠 优先级 让步 后台线程 加入一个线程 异常捕获 共享受限资源 休眠影响任务的一种简单方式是调用sleep（），这将使任务中止执行给定的时间。例程：123456789101112131415161718192021222324252627//: concurrency/SleepingTask.java// Calling sleep() to pause for a while.import java.util.concurrent.*;public class SleepingTask extends LiftOff &#123; public void run() &#123; try &#123; while(countDown-- &gt; 0) &#123; System.out.print(status()); // Old-style: // Thread.sleep(100); // Java SE5/6-style: TimeUnit.MILLISECONDS.sleep(100); &#125; &#125; catch(InterruptedException e) &#123; System.err.println("Interrupted"); &#125; &#125; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); for(int i = 0; i &lt; 5; i++) exec.execute(new SleepingTask()); exec.shutdown(); &#125;&#125; /* Output:#0(9), #1(9), #2(9), #3(9), #4(9), #0(8), #1(8), #2(8), #3(8), #4(8), #0(7), #1(7), #2(7), #3(7), #4(7), #0(6), #1(6), #2(6), #3(6), #4(6), #0(5), #1(5), #2(5), #3(5), #4(5), #0(4), #1(4), #2(4), #3(4), #4(4), #0(3), #1(3), #2(3), #3(3), #4(3), #0(2), #1(2), #2(2), #3(2), #4(2), #0(1), #1(1), #2(1), #3(1), #4(1), #0(Liftoff!), #1(Liftoff!), #2(Liftoff!), #3(Liftoff!), #4(Liftoff!),*///:~ 对sleep的调用可以抛出InterruptedException异常，并且你可以看到，它在main()中被捕获，因为异常不能跨越线程传播回main()，所以你必须在本地处理所有在任务内部产生的异常。 优先级线程的优先级先线程的重要性传递给调度器，尽管cpu处理现有线程集的顺序是不确定的，但是调度器更倾向于让优先级更高的线程先执行。线程优先级较低的线程不是不执行，仅仅是执行的频率较低。 getPriority()读取现有的优先级setPriority()来修改它 例程：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//: concurrency/SimplePriorities.java// Shows the use of thread priorities.import java.util.concurrent.*;public class SimplePriorities implements Runnable &#123; private int countDown = 5; private volatile double d; // No optimization private int priority; public SimplePriorities(int priority) &#123; this.priority = priority; &#125; public String toString() &#123; return Thread.currentThread() + ": " + countDown; &#125; public void run() &#123; Thread.currentThread().setPriority(priority); while(true) &#123; // An expensive, interruptable operation: for(int i = 1; i &lt; 100000; i++) &#123; d += (Math.PI + Math.E) / (double)i; if(i % 1000 == 0) Thread.yield(); &#125; System.out.println(this); if(--countDown == 0) return; &#125; &#125; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); for(int i = 0; i &lt; 5; i++) exec.execute( new SimplePriorities(Thread.MIN_PRIORITY)); exec.execute( new SimplePriorities(Thread.MAX_PRIORITY)); exec.shutdown(); &#125;&#125; /* Output: (70% match)Thread[pool-1-thread-6,10,main]: 5Thread[pool-1-thread-6,10,main]: 4Thread[pool-1-thread-6,10,main]: 3Thread[pool-1-thread-6,10,main]: 2Thread[pool-1-thread-6,10,main]: 1Thread[pool-1-thread-3,1,main]: 5Thread[pool-1-thread-2,1,main]: 5Thread[pool-1-thread-1,1,main]: 5Thread[pool-1-thread-5,1,main]: 5Thread[pool-1-thread-4,1,main]: 5...*///:~ 通过Thread.currentThread()来获取对驱动该任务的Thread对象的引用 尽管JDK有10个优先级，但它与多数操作系统都不能映射得很好，唯一可移植的方法是当调整优先级的时候。只使用 MAX_PRIORITY NORM_PRIORITY MIN_PRIORITY 三种级别 让步如果知道已经完成了在run()方法的循环的一次迭代过程中所需的工作，就可以给线程调度机制一个暗示：你的工作已近做的差不多了，可以让别的线程使用CPU了，这个暗示将通过调用yield()方法作出（不过这只是一个暗示，没有任何机制保证它将被采纳），当调用yield()时，你也是在建议具有相同优先级的其他线程可以运行 后台线程后台线程(deamon)线程，又叫守护线程，是指程序运行的时候在后台提供的一种通用服务线程。这种线程不属于程序中不可或缺的部分，因此，当所有非后台线程结束时，程序也就终止了，同时会杀死进程中的所有后台线程 必须在线程启动调用setDeamon()方法，才能把它设置为后台线程 例程：123456789101112131415161718192021222324252627282930313233343536373839//: concurrency/SimpleDaemons.java// Daemon threads don't prevent the program from ending.import java.util.concurrent.*;import static net.mindview.util.Print.*;public class SimpleDaemons implements Runnable &#123; public void run() &#123; try &#123; while(true) &#123; TimeUnit.MILLISECONDS.sleep(100); print(Thread.currentThread() + " " + this); &#125; &#125; catch(InterruptedException e) &#123; print("sleep() interrupted"); &#125; &#125; public static void main(String[] args) throws Exception &#123; for(int i = 0; i &lt; 10; i++) &#123; Thread daemon = new Thread(new SimpleDaemons()); daemon.setDaemon(true); // Must call before start() daemon.start(); &#125; print("All daemons started"); TimeUnit.MILLISECONDS.sleep(175); &#125;&#125; /* Output: (Sample)All daemons startedThread[Thread-0,5,main] SimpleDaemons@530daaThread[Thread-1,5,main] SimpleDaemons@a62fc3Thread[Thread-2,5,main] SimpleDaemons@89ae9eThread[Thread-3,5,main] SimpleDaemons@1270b73Thread[Thread-4,5,main] SimpleDaemons@60aeb0Thread[Thread-5,5,main] SimpleDaemons@16caf43Thread[Thread-6,5,main] SimpleDaemons@66848cThread[Thread-7,5,main] SimpleDaemons@8813f2Thread[Thread-8,5,main] SimpleDaemons@1d58aaeThread[Thread-9,5,main] SimpleDaemons@83cc67...*///:~ 可以调用isDeamon()方法来确定线程是否是一个后台线程，如果是一个后台线程，那么它创建的任何线程将被自动设置成后台线程 当最后一个非后台线程终止时，后台线程会“突然”终止。 加入一个线程一个线程在其他线程上调用join()方法，其效果是等待一段时间直到第二个线程结束才继续执行，如果某个线程在另一个线程t上调用t.join()，此线程将被挂起。直到目标线程t结束才恢复 也可以在调用join()时带上一个超时参数，这样如果目标线程在这段时间到期时还没有结束的话，join()方法总能返回。 对join()方法的调用可以被中断，做法是在线程上调用interrupt()方法，这需要用到try-catch子句 异常捕获由于线程的本质特性，使得你不能捕获从线程中逃逸的异常，一旦异常逃逸任务的run()方法，他就会向外传播到控制台，除非你采取特殊的步骤捕获这种错误的异常 Thread.UncaughtExceptionHandler是Java SE5中的新接口 ，它允许你在每个Thread对象上附着一个异常处理器 Thread.UncaughtExceptionHandler的uncaughtException()方法会在线程因未捕获的异常而临近死亡时被调用。 示例代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//: concurrency/CaptureUncaughtException.javaimport java.util.concurrent.*;class ExceptionThread2 implements Runnable &#123; public void run() &#123; Thread t = Thread.currentThread(); System.out.println("run() by " + t); System.out.println( "eh = " + t.getUncaughtExceptionHandler()); throw new RuntimeException(); &#125;&#125;class MyUncaughtExceptionHandler implementsThread.UncaughtExceptionHandler &#123; public void uncaughtException(Thread t, Throwable e) &#123; System.out.println("caught " + e); &#125;&#125;class HandlerThreadFactory implements ThreadFactory &#123; public Thread newThread(Runnable r) &#123; System.out.println(this + " creating new Thread"); Thread t = new Thread(r); System.out.println("created " + t); t.setUncaughtExceptionHandler( new MyUncaughtExceptionHandler()); System.out.println( "eh = " + t.getUncaughtExceptionHandler()); return t; &#125;&#125;public class CaptureUncaughtException &#123; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool( new HandlerThreadFactory()); exec.execute(new ExceptionThread2()); &#125;&#125; /* Output: (90% match)HandlerThreadFactory@de6ced creating new Threadcreated Thread[Thread-0,5,main]eh = MyUncaughtExceptionHandler@1fb8ee3run() by Thread[Thread-0,5,main]eh = MyUncaughtExceptionHandler@1fb8ee3caught java.lang.RuntimeException*///:~ 共享受限资源对于并发工作，你需要某种方式来防止两个任务访问相同的资源，至少关键阶段不能出现这种现象 基本上所有的并发模式在解决线程冲突问题的时候，都是采取序列化访问共享资源的方案 synchronizedJava以提供关键字synchronized的形式，为防止资源冲突提供了内置支持要控制对共享资源的访问，得先把它包装进一个对象 LockLock对象必须显示的创建、锁定和释放。与synchronized的形式的相比，代码缺乏优雅性。但是，对于解决某些类型的问题来说。它更加灵活。 如果使用synchronized关键字，某些事物失败了，那么就会抛出一个异常。但是你没有机会去做任何清理工作。以维护系统使其处于良好状态。有了显示的Lock对象，你就可以使用finally子句将系统维护在正常的状态了。 volatilezJVM可以将64位（long和double变量）读取和写入当做两个分离的32来执行，这就产生了一个在读取和写入操作中间发生上下文切换，从而导致不同任务可以看到不正确的结果的可能性（这有时被称为字撕裂） 当定义long和double变量时，如果使用volatile关键字，就会获取原子性 如果一个域完全由synchronized方法或语句块来保护，那就不必将其设置为是volatile的 当一个域的值依赖于它之前的值时，volatile就无法工作了。如果某个域的值受到其他域的值的限制。那么volatile也无法工作。使用volatile而不是synchronized的唯一安全的情况是类中只有一个可变的域。 同步控制块有时我们只希望防止多个线程同时访问方法内部的部分代码而不是防止访问整个方法，通过这种方式分离出来的代码段被称为临界区，她也使用synchronized关键字，这里synchronized被用来指定某对象，此对象的锁被用来对花括号内的代码进行同步控制 123synchronized(syncObject)&#123;&#125; 在进入此段代码前，必须得到syncObject对象的锁。如果其他线程也已经得到这个锁，那么就要等到锁被释放以后，才能进入临界区。 使用它的好处是，可以使多个任务访问对象的时间性能得到显著提高 ThreadLocal防止任务在共享资源上产生冲突的第二种方式是根除对变量的共享，线程本地是一种自动化机制，可以使用相同变量的每个不同线程都创建不同的存储， get()方法将返回与其线程相关联的对象的副本，而set()会将参数数据插入到为其线程储存的对象中。 （注：内容整理自《Thinking in Java》）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java多线程简介之基本概念、Thread类、Executor]]></title>
      <url>%2Fpost%2Fthinking-in-java-readnote-concurrent-01%2F</url>
      <content type="text"><![CDATA[在没有接触并发编程概念之前，你学到的都是有关顺序编程的知识，即程序中的所以事物在任意时刻都只能执行一个步骤并行编程可以使程序执行速度得到极大的提高，或者为设计某些类型的程序提供更易用的模型，或者两者皆有。当并行执行的任务彼此开始产生互相干涉时，实际的并发问题就会接踵而至。这些并发问题，如果视而不见，就会遭到其反噬。因此，使用并发时你得自食其力，并且只有变得多疑而且自信，才能用Java编写出可靠的多线程代码。 并发的多面性用并发解决的问题大体上可以分为“速度”和“设计可管理性”两种 如果程序中的某个任务因为改程序控制范围外的某些条件（通常是I/O）而导致不能继续执行，那么我们就说这个任务或线程阻塞了，如果没有并发，则整个程序都将停止下来，直至外部条件发生变化。但是，如果使用并发来编写程序，那么当一个任务发生阻塞时，程序中的其他任务还可以继续执行。因此这个任务可以保持继续向前执行。 实现并发最直接的方式就是操作系统级别的使用进程。进程是运行在它自己的地址空间内的自包容程序。 因此编写多线程程序最基本的困难在于协调不同线程驱动任务之间对这些资源的使用，以使得这些资源不会被多个任务访问。 某些编程语言被设计为可以将并发任务彼此隔离，这些语言通常为称为函数式语言，其中每个函数调用都不会产生任何副作用（并因此而不能干涉其他函数），并因此可以当作独立的任务驱动。 java的线程机制是抢占式的，这表示调度机会周期性地中断线程，将上下文切换到另一个线程，从而为每个线程都提供时间片，使得每个线程都会分配到数量合适的时间去驱动它的任务。在协作式系统中，每个任务都会自动的放弃控制，这要求程序员要有意识地在每个任务中插入某种类型的让步语句 基本的线程机制一个线程就是在进程中一个单一的顺序控制流，因此，单个进程可以拥有多个并发执行任务 定义任务要想定义一个任务，只需要实现Runnable接口并编写run()方法 例程：12345678910111213141516171819202122//: concurrency/LiftOff.java// Demonstration of the Runnable interface.public class LiftOff implements Runnable &#123; protected int countDown = 10; // Default private static int taskCount = 0; private final int id = taskCount++; public LiftOff() &#123;&#125; public LiftOff(int countDown) &#123; this.countDown = countDown; &#125; public String status() &#123; return "#" + id + "(" + (countDown &gt; 0 ? countDown : "Liftoff!") + "), "; &#125; public void run() &#123; while(countDown-- &gt; 0) &#123; System.out.print(status()); Thread.yield(); &#125; &#125;&#125; ///:~ Thread.yield() 的调用时对线程调度器的一种建议，它在声明：”我已经执行完生命周期中最重要的部分了，此刻正是切换给其他任务执行一段时间的大好时机“ 12345678910//: concurrency/MainThread.javapublic class MainThread &#123; public static void main(String[] args) &#123; LiftOff launch = new LiftOff(); launch.run(); &#125;&#125; /* Output:#0(9), #0(8), #0(7), #0(6), #0(5), #0(4), #0(3), #0(2), #0(1), #0(Liftoff!),*///:~ 当从Runable导出一个类时，它必须具有run()方法，但是这个方法并无特殊之处–它不会产生任何内在的线程能力，要实现线程行为，你必须显示的调用一个任务附着到线程上 Thread类Thread构造器只需要一个Runable对象，调用Thread对象的start()方法为该线程执行必须的初始化操作。 例程：12345678910111213//: concurrency/BasicThreads.java// The most basic use of the Thread class.public class BasicThreads &#123; public static void main(String[] args) &#123; Thread t = new Thread(new LiftOff()); t.start(); System.out.println("Waiting for LiftOff"); &#125;&#125; /* Output: (90% match)Waiting for LiftOff#0(9), #0(8), #0(7), #0(6), #0(5), #0(4), #0(3), #0(2), #0(1), #0(Liftoff!),*///:~ 注意：main()和LiftOff.run()是程序中与其他线程“同时”执行的代码。 使用Thread与使用普通实现Runable接口对象的区别？ 在使用普通对象时，这对于垃圾回收来说是一场公平的游戏，但是使用Thread时，情况就不同了，每个Thread都“注册”了它自己，因此确实有一个对它的引用。而且在它的任务退出其run()并死亡之前，垃圾回收期无法清除它。因此，一个线程会创建一个单独的执行线程，在对start()的调用完成之后。它仍然会继续存在 使用Executor在Java SE5的Java.util.concurrent包中的执行器（Executor）将为你管理Thread对象，Executor在客户端和任务执行之间提供了一个间接层Executor在Java SE 5/6 中是启动任务的优选方法。 例程：12345678910111213//: concurrency/CachedThreadPool.javaimport java.util.concurrent.*;public class CachedThreadPool &#123; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); for(int i = 0; i &lt; 5; i++) exec.execute(new LiftOff()); exec.shutdown(); &#125;&#125; /* Output: (Sample)#0(9), #0(8), #1(9), #2(9), #3(9), #4(9), #0(7), #1(8), #2(8), #3(8), #4(8), #0(6), #1(7), #2(7), #3(7), #4(7), #0(5), #1(6), #2(6), #3(6), #4(6), #0(4), #1(5), #2(5), #3(5), #4(5), #0(3), #1(4), #2(4), #3(4), #4(4), #0(2), #1(3), #2(3), #3(3), #4(3), #0(1), #1(2), #2(2), #3(2), #4(2), #0(Liftoff!), #1(1), #2(1), #3(1), #4(1), #1(Liftoff!), #2(Liftoff!), #3(Liftoff!), #4(Liftoff!),*///:~ 注意：ExecutorService对象是使用静态的Executor方法创建的，这个方法可以确定Executor的类型，类型有CachedThreadPool，FixedThreadPool，SingleThreadPool。 shutdown()方法的调用可以防止新任务被提交给这个Executor，当前线程将继续执行在shutdown()被调用之前提交的所以任务，这个程序将在Executor中的所有任务完成之后尽快退出。 FixedThreadPool使用了有限的线程集来执行所提交的任务。例程：1234567891011121314//: concurrency/FixedThreadPool.javaimport java.util.concurrent.*;public class FixedThreadPool &#123; public static void main(String[] args) &#123; // Constructor argument is number of threads: ExecutorService exec = Executors.newFixedThreadPool(5); for(int i = 0; i &lt; 5; i++) exec.execute(new LiftOff()); exec.shutdown(); &#125;&#125; /* Output: (Sample)#0(9), #0(8), #1(9), #2(9), #3(9), #4(9), #0(7), #1(8), #2(8), #3(8), #4(8), #0(6), #1(7), #2(7), #3(7), #4(7), #0(5), #1(6), #2(6), #3(6), #4(6), #0(4), #1(5), #2(5), #3(5), #4(5), #0(3), #1(4), #2(4), #3(4), #4(4), #0(2), #1(3), #2(3), #3(3), #4(3), #0(1), #1(2), #2(2), #3(2), #4(2), #0(Liftoff!), #1(1), #2(1), #3(1), #4(1), #1(Liftoff!), #2(Liftoff!), #3(Liftoff!), #4(Liftoff!),*///:~ 有了FixedThreadPool在事件驱动的系统中，需要线程的事件处理器，通过直接从池中获取线程，也可以如你所愿地尽快的得到服务。你不会滥用可获得的资源。 SingleThreadPool就像是数量为1的FixedThreadPool向SingleThreadPool提交多个任务，那么这些任务将排队，每个任务都会在下一个任务开始之前结束。所有的任务将使用相同的线程。 从任务产生返回值Runnable不返回任何值，如果希望任务在完成时能够返回一个值。那么可以实现Callable接口,在Java SE5中引入的Callable是一种具有参数类型的泛型，它从方法call()中返回值，必须使用ExecutorService.submit()方法调用它。 例程：12345678910111213141516171819202122232425262728293031323334353637383940414243444546//: concurrency/CallableDemo.javaimport java.util.concurrent.*;import java.util.*;class TaskWithResult implements Callable&lt;String&gt; &#123; private int id; public TaskWithResult(int id) &#123; this.id = id; &#125; public String call() &#123; return "result of TaskWithResult " + id; &#125;&#125;public class CallableDemo &#123; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); ArrayList&lt;Future&lt;String&gt;&gt; results = new ArrayList&lt;Future&lt;String&gt;&gt;(); for(int i = 0; i &lt; 10; i++) results.add(exec.submit(new TaskWithResult(i))); for(Future&lt;String&gt; fs : results) try &#123; // get() blocks until completion: System.out.println(fs.get()); &#125; catch(InterruptedException e) &#123; System.out.println(e); return; &#125; catch(ExecutionException e) &#123; System.out.println(e); &#125; finally &#123; exec.shutdown(); &#125; &#125;&#125; /* Output:result of TaskWithResult 0result of TaskWithResult 1result of TaskWithResult 2result of TaskWithResult 3result of TaskWithResult 4result of TaskWithResult 5result of TaskWithResult 6result of TaskWithResult 7result of TaskWithResult 8result of TaskWithResult 9*///:~ （注：内容整理自《Thinking in Java》）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用Redis构建web应用]]></title>
      <url>%2Fpost%2Fredisinaction_readnote_02%2F</url>
      <content type="text"><![CDATA[登录和cookie缓存 购物车 网页缓存 数据行缓存 网页分析 代码格式有问题，见谅 目录 登录和cookie缓存cookie：当我们登录互联网服务的时候，这些服务都会使用cookie来记录我们的身份，cookie由少量数据组成，网站会要求我们的浏览器存储这些数据，并在每次服务发生请求时将这些数据传回给服务 对于用来登录的cookie，有两种方法可以将登录信息储存在cookie里面，一种是签名（signed）cookie一种是令牌（token）cookie 签名cookie通常会储存用户名，还可能有用户ID，用户最后一次成功登录的时间，以及网站觉得有用的其他信息，除此之外，cookie还会包含一个签名，服务器可以用它来验证浏览器发生的信息是否被改动（比如cookie中的登录用户名改成另一个用户） 令牌cookie会在cookie里面储存一串随机字节作为令牌，服务器可以根据令牌在数据库中查找令牌的拥有者，随着时间的推移，旧令牌会被新令牌取代 redis实现令牌登录cookie：首先，我们将使用一个hash来储存登录cookie令牌和已登录用户之间的映射，要检查一个用户是否已经登录，需要根据给定的令牌来查找与之对应的用户，并在用户已经登录的情况下，返回该用户的id 尝试获取并返回令牌对应的用户12def check_token(conn,token): return conn.hget('login:',token) 更新令牌：用户每次浏览页面的时候，程序都会对用户存储在登录hash里面的信息进行更新，并将用户的令牌和当前时间戳添加到记录最近登录用户的有序集合里面，如果用户正在浏览一个商品页面，那么程序还会将这个商品添加到记录这个用户最近浏览过的商品的有序集合里面，并在被记录的商品的数量超过25个时，对这个有序集合进行修剪 1234567def update_token(conn,token,user,item=None): timestamp = time.time() //获取当前时间戳 conn.hset('login:',token,user) //维持令牌与用户之间的映射 conn.zadd('recent',token,timestamp)//记录令牌最后一次出现的时间 if item： conn.zadd('viewed:'+token,item,timestamp) //记录用户浏览过的商品 conn.zremrangebyrank('viewed:'+token,0,-26)//移除旧的记录，只保存用户浏览过的25个商品 储存会话的数据所需的内存会随着时间的推移不断增加，需要清理旧数据，只保存1000万个，清理程序是一个循环，检查集合的大小，超过了限制就移除最多100个旧令牌，并移除记录用户信息的hash信息，并清除浏览信息。如果没有要清理的，休眠1秒，在检查(附：使用redis过期时间，就可以在一段时间之后让redis自动删除他们) 12345678910111213141516171819202122 QUIT = False LIMIT = 10000000 def clean_sessions(conn): while not QUIT://找出目前已有令牌的数量size = conn.zcard('recent:') //令牌数量未超过限制，休眠并在之后重新检查if size &lt;= LIMIT: time.sleep(1) continue//获取需要移除的令牌idend_index = min(size-LIMIT,100)tokens = conn.zrange('recent:',0,end_index-1)//为那些要被删除的令牌构建键名session_keys = [] for token in tokens: session_keys.append(‘viewed:’+token)//移除旧的那些令牌conn,delete(*session_keys)conn.hdel('login:',*tokens)conn.zrem('recent',*tokens) 购物车每个用户的购物车是一个散列，这个散列储存了商品ID与商品订购数量之间的映射，对商品数量验证的工作由web应用程序复杂，我们要做的是在商品的订购数量发生变化的时候，对购物车进行更新12345 def add_to_cart(conn,session,count)if count &lt;=0; conn.hrem('cart:'+session,item)else conn.hset('cart:'+session,item,count) 网页缓存1234567891011121314def cache_request(conn,request,callback): //对于不用背缓存的请求，直接调用回调函数 if not can_cache(conn,request); return callback(request) //将请求装换成一个简单的字符串建。方便之后进 行查找 page_key = 'cache:'+hash_request(request) //查找被缓存的页面 content = conn.get(request) //如果页面还没有被缓存，那么生成页面 if not content: content=callback(request) //将新生成的页面放到缓存里 conn.setex(page_key,content,300) return content 数据行缓存为了应对促销活动带来的大量负载，我们需要对数据进行缓存，具体的做法是：编写一个持续运行的守护进程函数，让这个函数将指定数据行缓存到redis里面，并不定期地对缓存进行更新，数据将被转为json储存在redis的字符串里 程序使用了两个zset，来记录应该在何时何地对缓存进行更新：第一个有序集合为调度有序集合，它的成员为数据行的行id，而分值是一个时间戳，记录了应该在何时将指定的数据行缓存到redis里面，第二个有序集合为延时zset，它的成员也是数据行的行id，而分值则记录了指定数据行的缓存需要每隔多少秒更新一次 调度缓存和终止缓存的函数12345def schedule_row_cache(conn,row_id,delay): //先设置数据行的延迟值 conn.zadd('delay',row_id,delay) //立即对需要缓存的数据进行调度 conn.zadd('schedule‘，row_id,time.time()) 复杂缓存数据的函数1234567891011121314151617181920212223def cache_rows(conn): while not QUIT: //尝试获取下一个需要被缓存的数据行以及该行的调度时间戳，命令会返回一个包含零个或一个元组的列表 next = conn.zrange('schedule:',0,0,withscores=Ture) now = time.time() //暂时没有行需要被缓存，休眠60ms后重试 if not next or next[0][1]&gt;row time.sleep(.05) continue row_id = next[0][0] //提前获取下一次调度的延迟时间 delay=conn.zscore('delay',row_id) if delay &lt;=0: //不必缓存这个行，从他从缓存中移除 conn.zrem('delay:',row_id) conn.zrem('schedule:',row_id) conn.delete('inv:'+row_id) continue //读取数据行，更新调度时间并设置缓存值 row = Inventory.get(row_id) conn.zadd('schedule:',row_id,now+delay) conn.set('inv'+row_id,json.dump(row.to_dict())) 网页分析在原来的update_token中12345678 def update_token(conn,token,user,item=None): timestamp = time.time() //获取当前时间戳 conn.hset('login:',token,user) //维持令牌与用户之间的映射 conn.zadd('recent',token,timestamp)//记录令牌最后一次出现的时间if item： conn.zadd('viewed:'+token,item,timestamp) //记录用户浏览过的商品 conn.zremrangebyrank('viewed:'+token,0,-26)//移除旧的记录，只保存用户浏览过的25个商品 conn.zincrby('viewed:'item,-1) 新添加的代码记录了商品的浏览次数，并根据浏览次数对商品进行了排序，被浏览的最多的商品将被放在有序集合的索引0的位置上，并且具有最少的分值为了让商品浏览次数保持最新，我们需要定期修剪有序集合的长度并调整已有元素的分值，从而使得新流行的商品也可以在排行榜里面占据一席之地 1234567def rescale_viewed(conn); while not QUIT: //删除所有牌面在2万名之后的商品 conn.zremrangebyrank('viewed',0,-20001) //将浏览次数降低为原来的一般 conn,zinterstore('viewed:' .5) time.sleep(300) 修改之前的的can_cache()函数12345678910 def can_cache(conn request); //尝试从页面里面获取商品id item_id = extract_itrm_id(request) //检查这个页面能否被缓存已经这个页面是否为商品页面 if not item_id or is_dynamic(request);return False //获取商品的浏览次数牌面 rank = conn,zrank('viewed',item_id) 根据排名判断是否需要被缓存 return rank is not None and rank&lt;10000 （注：内容整理自《redis实战》）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[《年轻可以一无所有》读书笔记]]></title>
      <url>%2Fpost%2Fyouth%2F</url>
      <content type="text"><![CDATA[青春五千日 人生三万天 你要盯住有限的几个机会，把手艺越磨越精，最后才能再众多对手的竞争中胜出，速成文化，也许让位与专精文化。年轻人的心态要改。不是什么事情稍微玩儿几年就会成大器的。你也许真要“十年磨一剑”，甚至在此之后还要付出长年的努力，最终才会有理想的结果。 在一个正常的社会，年轻人就是应该一无所有的。难道生活刚起步，就应该指望别人给你许多许多吗？拜托，你有没有想过给了别人什么？凭什么向别人索取。 大家总是盯着自己没有的东西，并为之死去活来的争，恨不得把什么都搭上，却不珍视自己所拥有的，不觉得那有什么价值。《纽约时报》著名专栏作家戴维布鲁克斯又一次吐露了真言：大概所以功成名就的中年人，都宁愿把自己的金钱和地位统统放弃来换回年轻！ 但我知道有两样东西属于我的私有产权，别人想侵占也不可能：一是知识，一是健康。我正式因为精心守护这两样东西，而碰到了后来成为妻子的美丽女友–对方居然和我一样一无所有。 当你买任何一件自己不真正需要的东西时，就开始接受这个东西的奴役了。 要尽可能把青春全部投入自己的发展，而不是廉价拍卖。 成长首先意味着和比自己年纪大的人相处，听他们的教诲。 生活的速度比虚拟世界中的速度慢的多，我从小听着“十年寒窗”“十年磨一剑”“十年冷板凳”之类的教训。于是总看着10年以后的图景。惦记着生活何时开始：28岁学英文，是为了生活做准备；34岁拿到教职，觉得生活刚刚开始；如今年过半百。觉得一生大部分的事情尚未启动。我相信。20年后我大概会效法许多美国人，以退休迎接人生的另一个开端，一个充满了创造和快乐的开端。这并不是觉得自己能干多么惊天动地的事情，而是觉得只要足够长的时间准备，就会有所得。就会有东西贡献出来。 生活中右许多现成的东西早该在那里等着自己。就像在网络上那样。只需要点击一个“喜欢”或“不喜欢”。他们似乎没有想明白：生活中本没有那么简单的点击键。当他们找不到这样的点击键时，似乎就不知道该怎么生活了。 你们老的太快，因为你们对自己成长期待太急切，因为你们沉溺于虚拟世界。忘了真实的生活是什么样子。 如果你们总是以扎克伯格，乔布斯为样板树立自己的生活的目标，觉得一个技艺高超可靠的老技工不足道也，如果你们期待这以网络般的速度和戏剧感达到这样的目标，那么，更可能发生的是：你们很年轻的时候就觉得自己错过了人生，早早就觉得自己成为无足轻重的屌丝。 一生中真正的朋友用五个手指头就可以数过来 我们花同样的甚至更多的时间，去追逐那些我们很少接触的好友，冷落的则是我们所爱的人 登山是为了看世界，而不是让世界看你。 友情是除了智慧之外，人所能得到的最好的礼物。 过度的受同龄人的影响，错过了想长辈学习的机会，不要连向同龄人学习的机会也错过，你余下的一生，不是对16岁时就形成的自我不停地玩味品尝、没有终结得自爱。如果你能从虚拟世界中出来，看看身边，也许你会马上发现“三人行必有我师”也许你会不停地翻上一座又一座的高山，超越自己既有的生活眼界。 如果被体制耽误的同时，还自己耽误自己，那可就真是青春荒芜了 即刻行动才是王道，这里有一个底线，就是自食其力，在此基础上，再设计未来的计划。 青春首先不能荒芜，日后才能开花结果 工作是生活的一个立脚点，有了这个立脚点，就要为自己的未来经营。给自己不停地充电。 每天在办公室加班到半夜十一二点，干的又是下层白领的简单劳动，自身还怎么发展？自身不发展，还怎么升值？ 发展出一套清晰的人生哲学还是非常重要的，这会帮助你在具体的环境中明智地权衡得失。 这需要你在一个高度物质化得攀比时代，能够保持自信和淡定。如果你一看见同学买车，买房就内心沉沦，你怎么可以专注于自己？俗话说，有所得，必有所失。你不懂得舍弃，就很难获得 年轻人应该意识到，房子、车子这类东西，未必能搞界定人的幸福感，而且现在没有，以后也可以有，毕竟这些都是可以靠金钱买来的。但是，你还有两样更珍贵的东西：健康和知识（或者说本事）。这些不是有钱就可以买到的，需要你不停地用生命来投入。 怎么超脱世俗世界对物质的追逐？以我自己的经验，最简单的办法就是眼望未来，当你有了“我是属于未来的人”的定位后，对于眼前的得失就会有一种类似出世的解脱心态。年轻人日后的路比我们长得多。做的这一点也更容易些。这就是青春的力量。 那些教育水平比较高、职业地位比较高、中高收入的阶层，往往经受着更大的心理压力。 中国人之间的攀比也特别强。穿什么牌子，开什么车，住什么房子，似乎都是个事，大家比来比去，总觉得自己还不够有实力，心里愈发焦急。 人如果能“看破红尘”一些，别在乎那些别人都特别在乎的事情，生活开销会少不少，压力会减轻很多，幸福感会提高，当然也就会更健康了。总之，成功如果仅仅是别人的期待的话，那就不值得你为之付出那么多。 对屌丝心态的一个最直接的解释，恐怕就是一个破罐破摔的心态，这种心态的一个后果，就是无所谓，满不在乎，最终导致对社会主流价值的拒绝和反叛，这也是主流社会对之戒备的理由。 社会给一个人的回报，不是看你关系了自己多少，为自己争夺利益和报酬，而是看你关系了别人多少，为别人提供了多少有价值的服务。中国的年轻一代，一旦接受了这种用物质来界定成功的价值观念，就会从一开始就追求最低层级的满足，限制自己的人生视野，一生往往会在低层级的境界中转悠。 那种一次性事件带来的幸福感，仅仅停留在那个时刻，几个月后就会消失，即使你为了那个时刻奋斗了许多年，所以，剩下的12%，虽然看起来分量不大，实际上却非常重要，那就是信仰、家庭、社区、和工作这四方面的价值。 寻求低层次的满足、不管你有多满足，还是很低的满足。 如果你根据自己拥有的东西来衡量成功，并有很大的成功和赚钱的压力，那么在你眼前，这一切就都是破产的买卖。再自我反省一下，我们中国人，似乎每个人都是理财大师，看着美国人这么冒傻气会偷偷地笑。然而，当把一切都化约为理财时，我们就丧失了自己的生活和生活的幸福。 《独立宣言》上标举“生命、自由和追求幸福的权利”为什么是“追求幸福的权利”而不是“幸福的权利”？因为“幸福”不是一个理所应得的东西。你有追求的自由，但不能指望别人担保你就一定能得到，你更不能因为你自己的要求没有获得满足，就觉得自己是天下最不幸的人。 走出自己的舒适域，这样才能进步。 自己待会儿，即所谓独处，本事人格形成的重要环节。丧失了这样的机会。后果又是什么呢？恐怕，现在大部分人都忘记了这回事。 而今中国的年轻一代，有太多太多人从小就紧张地东张西望，生怕自己错过什么，最终，他们所错过的，恰恰是自己。 在学业、事业等技术细节上，年轻人应该尽可能自己寻求解决问题的答案，但是，在人格的塑造、品性的培养等素质层面，“老人言”往往会提供一个明确的指南。 现在的年轻人中，那种被称为出息的人，往往合乎上述的规范。他们属于家长基本上不用操心的孩子，因为他们在学业等具体事务上，都能自己安排得井井有条，比家长更会处理。但其做人的基本品信往往受长辈影响。和家长沟通得也比较好。那些被称为没出息的人。则几乎完全倒过来。在做人的基本品性上，他们非常讨厌大人的教导。比如要用功一点。持之以恒等教诲，在他们看来都是愚不可及的道德说教。他们我行我素，甚至会对父母颐指气使。但是，真要办具体的事情，则几乎完全拜托家长。比如托家长的关系获得种种机会，让家长花钱送自己去留学，等等。也就是说。他们不听老人言。但是要老子钱。 苏格拉底说：“满足于最少的所得的人，才是最富足的” 他们只看到自己得到了什么，并拿这个比来比去，从来不相信自己付出什么，从来不想想看自己能从内心中掏出什么东西来献给这个世界。因为他们内心太贫乏了。哪里有东西与别人分享？这让我想起西方的谚语：“虽然一个没钱的人很穷，但除了钱以为什么都没有的人更穷” 学生在没有走向社会前，总觉得世界以自己为中心。但一求职就知道，世界是以别人为中心，而且这些别人还动不动就把你扔进纸篓，你事业的起步，首先是要证明你不是垃圾。做到这一点还并不是那么容易。要闯荡世界。就要从建立这样的认识开始。 出来见识多了就知道，聪明人实在太多了，自己算不上老几。这些聪明绝顶人之间还要竞争，最终成功的还是少数，往往是那些没有和杰出人才直接打交道的，更容易对所谓天生才能迷信备至。 对压力的心理反应，往往取决于我们事先的期待。是吧压力当成生活中必要的挑战，并为这样的挑战感到兴奋，还是把压力视为洪水猛兽，动不动就觉得压力超过自己的承受极限，这在很大程度上决定了我们在压力之下的心理和生理健康。 人的潜力总是比自己想象得要大。自信能够帮助人最大限度地发挥这种潜力 人生是一场马拉松，青春算是起跑，作为马拉松迷，我看了那么多著名的比赛，还没有一次看到起跑时领先的人最后拿了冠军的。最后拿了冠军的人，往往都是开始特别淡定。跟在别人后面。调整自己的身体。以我的经验看，青春期最重要的就是培养自己的品信和习惯。这比具体学到什么东西还重要。 其中特别重要的猛攻自己的弱项，当一个人发现经过努力，在自己的弱项上也可以不弱时，就更有信心和勇气去迎接更大的挑战。一旦品性和习惯养成，形成指导自己一生的准则，十几年后就会赢。 现在我们学到的所以东西，随时有可能随着知识更新而变得废弃无用，但是，强健的人格则是面对变幻不定的挑战的最好本钱。 发展有效的学习能力，学习习惯，比具体学到的东西更为重要。 为什么是我？因为我要干一些大部分人都不会干的事情。 接受一个理念很容易，但培养一个习惯却很难。 西方有句谚语总结得更为精到：“留意你的思想，因为思想会变成言辞。留意你的言辞，因为言辞会变成行动。留意你的行动，因为行动会变成习惯。留意你的习惯，因为习惯会变为品格，留意你的品格，因为品格会变成你的命运” 你目前的境遇不会决定你走到哪里，而只是决定你的起点。 境遇本身无法造就一个人，而只是揭示一个人。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[【转】Java ThreadLocal 简介]]></title>
      <url>%2Fpost%2FJava-ThreadLocal%2F</url>
      <content type="text"><![CDATA[ThreadLocal在Spring中发挥着重要的作用，在管理request作用域的Bean、事务管理、任务调度、AOP等模块都出现了它们的身影，起着举足轻重的作用。要想了解Spring事务管理的底层技术，ThreadLocal是必须攻克的山头堡垒。 我们知道spring通过各种模板类降低了开发者使用各种数据持久技术的难度。这些模板类都是线程安全的，也就是说，多个DAO可以复用同一个模板实例而不会发生冲突。我们使用模板类访问底层数据，根据持久化技术的不同，模板类需要绑定数据连接或会话的资源。但这些资源本身是非线程安全的，也就是说它们不能在同一时刻被多个线程共享。虽然模板类通过资源池获取数据连接或会话，但资源池本身解决的是数据连接或会话的缓存问题，并非数据连接或会话的线程安全问题。 按照传统经验，如果某个对象是非线程安全的，在多线程环境下，对对象的访问必须采用synchronized进行线程同步。但模板类并未采用线程同步机制，因为线程同步会降低并发性，影响系统性能。此外，通过代码同步解决线程安全的挑战性很大，可能会增强好几倍的实现难度。那么模板类究竟仰仗何种魔法神功，可以在无须线程同步的情况下就化解线程安全的难题呢？答案就是ThreadLocal！ ThreadLocal在Spring中发挥着重要的作用，在管理request作用域的Bean、事务管理、任务调度、AOP等模块都出现了它们的身影，起着举足轻重的作用。要想了解Spring事务管理的底层技术，ThreadLocal是必须攻克的山头堡垒。 ThreadLocal是什么早在JDK 1.2的版本中就提供Java.lang.ThreadLocal，ThreadLocal为解决多线程程序的并发问题提供了一种新的思路。使用这个工具类可以很简洁地编写出优美的多线程程序。ThreadLocal，顾名思义，它不是一个线程，而是线程的一个本地化对象。当工作于多线程中的对象使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程分配一个独立的变量副本。所以每一个线程都可以独立地改变自己的副本，而不会影响其他线程所对应的副本。从线程的角度看，这个变量就像是线程的本地变量，这也是类名中“Local”所要表达的意思。 线程局部变量并不是Java的新发明，很多语言（如IBM XL、FORTRAN）在语法层面就提供线程局部变量。在Java中没有提供语言级支持，而以一种变通的方法，通过ThreadLocal的类提供支持。所以，在Java中编写线程局部变量的代码相对来说要笨拙一些，这也是为什么线程局部变量没有在Java开发者中得到很好普及的原因。 ThreadLocal的接口方法ThreadLocal类接口很简单，只有4个方法，我们先来了解一下。void set(Object value)设置当前线程的线程局部变量的值；public Object get()该方法返回当前线程所对应的线程局部变量；public void remove()将当前线程局部变量的值删除，目的是为了减少内存的占用，该方法是JDK 5.0新增的方法。需要指出的是，当线程结束后，对应该线程的局部变量将自动被垃圾回收，所以显式调用该方法清除线程的局部变量并不是必须的操作，但它可以加快内存回收的速度；protected Object initialValue()返回该线程局部变量的初始值，该方法是一个protected的方法，显然是为了让子类覆盖而设计的。这个方法是一个延迟调用方法，在线程第1次调用get()或set(Object)时才执行，并且仅执行1次。ThreadLocal中的默认实现直接返回一个null。 值得一提的是，在JDK5.0中，ThreadLocal已经支持泛型，该类的类名已经变为ThreadLocal。API方法也相应进行了调整，新版本的API方法分别是void set(T value)、T get()以及T initialValue()。 ThreadLocal是如何做到为每一个线程维护变量的副本的呢？其实实现的思路很简单：在ThreadLocal类中有一个Map，用于存储每一个线程的变量副本，Map中元素的键为线程对象，而值对应线程的变量副本。我们自己就可以提供一个简单的实现版本： 代码清单9-3 SimpleThreadLocal1234567891011121314151617181920212223242526public class SimpleThreadLocal &#123; private Map valueMap = Collections.synchronizedMap(new HashMap()); public void set(Object newValue) &#123; //①键为线程对象，值为本线程的变量副本 valueMap.put(Thread.currentThread(), newValue); &#125; public Object get() &#123; Thread currentThread = Thread.currentThread(); //②返回本线程对应的变量 Object o = valueMap.get(currentThread); //③如果在Map中不存在，放到Map中保存起来 if (o == null &amp;&amp; !valueMap.containsKey(currentThread)) &#123; o = initialValue(); valueMap.put(currentThread, o); &#125; return o; &#125; public void remove() &#123; valueMap.remove(Thread.currentThread()); &#125; public Object initialValue() &#123; return null; &#125; &#125; 虽然代码清单9 3中这个ThreadLocal实现版本显得比较幼稚，但它和JDK所提供的ThreadLocal类在实现思路上是非常相近的。 一个TheadLocal实例下面，我们通过一个具体的实例了解一下ThreadLocal的具体使用方法。代码清单9-4 SequenceNumber 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.baobaotao.basic; public class SequenceNumber &#123; //①通过匿名内部类覆盖ThreadLocal的initialValue()方法，指定初始值 private static ThreadLocal&lt;Integer&gt; seqNum = new ThreadLocal&lt;Integer&gt;()&#123; public Integer initialValue()&#123; return 0; &#125; &#125;; //②获取下一个序列值 public int getNextNum()&#123; seqNum.set(seqNum.get()+1); return seqNum.get(); &#125; public static void main(String[ ] args) &#123; SequenceNumber sn = new SequenceNumber(); //③ 3个线程共享sn，各自产生序列号 TestClient t1 = new TestClient(sn); TestClient t2 = new TestClient(sn); TestClient t3 = new TestClient(sn); t1.start(); t2.start(); t3.start(); &#125; private static class TestClient extends Thread &#123; private SequenceNumber sn; public TestClient(SequenceNumber sn) &#123; this.sn = sn; &#125; public void run() &#123; //④每个线程打出3个序列值 for (int i = 0; i &lt; 3; i++) &#123; System.out.println("thread["+Thread.currentThread().getName()+ "] sn["+sn.getNextNum()+"]"); &#125; &#125; &#125; &#125; 通常我们通过匿名内部类的方式定义ThreadLocal的子类，提供初始的变量值，如①处所示。TestClient线程产生一组序列号，在③处，我们生成3个TestClient，它们共享同一个SequenceNumber实例。运行以上代码，在控制台上输出以下的结果： thread[Thread-2] sn[1]thread[Thread-0] sn[1]thread[Thread-1] sn[1]thread[Thread-2] sn[2]thread[Thread-0] sn[2]thread[Thread-1] sn[2]thread[Thread-2] sn[3]thread[Thread-0] sn[3]thread[Thread-1] sn[3] 考查输出的结果信息，我们发现每个线程所产生的序号虽然都共享同一个Sequence Number实例，但它们并没有发生相互干扰的情况，而是各自产生独立的序列号，这是因为我们通过ThreadLocal为每一个线程提供了单独的副本。 与Thread同步机制的比较ThreadLocal和线程同步机制相比有什么优势呢？ThreadLocal和线程同步机制都是为了解决多线程中相同变量的访问冲突问题。 在同步机制中，通过对象的锁机制保证同一时间只有一个线程访问变量。这时该变量是多个线程共享的，使用同步机制要求程序缜密地分析什么时候对变量进行读写，什么时候需要锁定某个对象，什么时候释放对象锁等繁杂的问题，程序设计和编写难度相对较大。 而ThreadLocal则从另一个角度来解决多线程的并发访问。ThreadLocal为每一个线程提供一个独立的变量副本，从而隔离了多个线程对访问数据的冲突。因为每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的对象封装，在编写多线程代码时，可以把不安全的变量封装进ThreadLocal。 由于ThreadLocal中可以持有任何类型的对象，低版本JDK所提供的get()返回的是Object对象，需要强制类型转换。但JDK 5.0通过泛型很好的解决了这个问题，在一定程度上简化ThreadLocal的使用，代码清单9-2就使用了JDK 5.0新的ThreadLocal版本。 概括起来说，对于多线程资源共享的问题，同步机制采用了“以时间换空间”的方式：访问串行化，对象共享化。而ThreadLocal采用了“以空间换时间”的方式：访问并行化，对象独享化。前者仅提供一份变量，让不同的线程排队访问，而后者为每一个线程都提供了一份变量，因此可以同时访问而互不影响。 Spring使用ThreadLocal解决线程安全问题我们知道在一般情况下，只有无状态的Bean才可以在多线程环境下共享，在Spring中，绝大部分Bean都可以声明为singleton作用域。就是因为Spring对一些Bean（如RequestContextHolder、TransactionSynchronizationManager、LocaleContextHolder等）中非线程安全的“状态性对象”采用ThreadLocal进行封装，让它们也成为线程安全的“状态性对象”，因此有状态的Bean就能够以singleton的方式在多线程中正常工作了。 一般的Web应用划分为展现层、服务层和持久层三个层次，在不同的层中编写对应的逻辑，下层通过接口向上层开放功能调用。在一般情况下，从接收请求到返回响应所经过的所有程序调用都同属于一个线程，如图9-2所示。这样用户就可以根据需要，将一些非线程安全的变量以ThreadLocal存放，在同一次请求响应的调用线程中，所有对象所访问的同一ThreadLocal变量都是当前线程所绑定的。下面的实例能够体现Spring对有状态Bean的改造思路： 代码清单9-5 TopicDao：非线程安全123456789public class TopicDao &#123; //①一个非线程安全的变量 private Connection conn; public void addTopic()&#123; //②引用非线程安全变量 Statement stat = conn.createStatement(); … &#125; &#125; 由于①处的conn是成员变量，因为addTopic()方法是非线程安全的，必须在使用时创建一个新TopicDao实例（非singleton）。下面使用ThreadLocal对conn这个非线程安全的“状态”进行改造： 代码清单9-6 TopicDao：线程安全12345678910111213141516171819202122232425import java.sql.Connection; import java.sql.Statement; public class TopicDao &#123; //①使用ThreadLocal保存Connection变量 private static ThreadLocal&lt;Connection&gt; connThreadLocal = new ThreadLocal&lt;Connection&gt;(); public static Connection getConnection()&#123; //②如果connThreadLocal没有本线程对应的Connection创建一个新的Connection， //并将其保存到线程本地变量中。 if (connThreadLocal.get() == null) &#123; Connection conn = ConnectionManager.getConnection(); connThreadLocal.set(conn); return conn; &#125;else&#123; //③直接返回线程本地变量 return connThreadLocal.get(); &#125; &#125; public void addTopic() &#123; //④从ThreadLocal中获取线程对应的 Statement stat = getConnection().createStatement(); &#125; &#125; 不同的线程在使用TopicDao时，先判断connThreadLocal.get()是否为null，如果为null，则说明当前线程还没有对应的Connection对象，这时创建一个Connection对象并添加到本地线程变量中；如果不为null，则说明当前的线程已经拥有了Connection对象，直接使用就可以了。这样，就保证了不同的线程使用线程相关的Connection，而不会使用其他线程的Connection。因此，这个TopicDao就可以做到singleton共享了。 当然，这个例子本身很粗糙，将Connection的ThreadLocal直接放在Dao只能做到本Dao的多个方法共享Connection时不发生线程安全问题，但无法和其他Dao共用同一个Connection，要做到同一事务多Dao共享同一个Connection，必须在一个共同的外部类使用ThreadLocal保存Connection。但这个实例基本上说明了Spring对有状态类线程安全化的解决思路。在本章后面的内容中，我们将详细说明Spring如何通过ThreadLocal解决事务管理的问题。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[【转】Java注解简介]]></title>
      <url>%2Fpost%2FJava-annotation-introduction%2F</url>
      <content type="text"><![CDATA[有必要对JDK 5.0新增的注解（Annotation）技术进行简单的学习，因为spring 支持@AspectJ，而@AspectJ本身就是基于JDK 5.0的注解技术。所以学习JDK 5.0的注解知识有助于我们更好地理解和掌握Spring的AOP技术。 了解注解对于Java开发人员来说，在编写代码时，除了源程序以外，我们还会使用Javadoc标签对类、方法或成员变量进行注释，以便使用Javadoc工具生成和源代码配套的Javadoc文档。这些@param、@return等Javadoc标签就是注解标签，它们为第三方工具提供了描述程序代码的注释信息。使用过Xdoclet的朋友，对此将更有感触，像Struts、hibernate都提供了Xdoclet标签，使用它们可以快速地生成对应程序代码的配置文件。 JDK5.0注解可以看成是Javadoc标签和Xdoclet标签的延伸和发展。在JDK5.0中，我们可以自定义这些标签，并通过Java语言的反射机制中获取类中标注的注解，完成特定的功能。注解是代码的附属信息，它遵循一个基本原则：注解不能直接干扰程序代码的运行，无论增加或删除注解，代码都能够正常运行。Java语言解释器会忽略这些注解，而由第三方工具负责对注解进行处理。第三方工具可以利用代码中的注解间接控制程序代码的运行，它们通过Java反射机制读取注解的信息，并根据这些信息更改目标程序的逻辑，而这正是Spring AOP对@AspectJ提供支持所采取的方法。 很多东西的设计都必须遵循最基本的原则，为了防止机器人伤害人类，科幻作家阿西莫夫于1940年提出了“机器人三原则”：第一，机器人不能伤害人类；第二，机器人应遵守人类的命令，与第一条违背的命令除外；第三，机器人应能保护自己，与第一条违背的命令除外。这是给机器人赋予的伦理性纲领，机器人学术界一直将这三条原则作为机器人开发的准则。 一个简单的注解类通常情况下，第三方工具不但负责处理特定的注解，本身还提供了这些注解的定义，所以我们通常仅需关注如何使用注解就可以了。但定义注解类本身并不困难，Java提供了定义注解的语法。下面，我们马上着手编写一个简单的注解类，如代码清单7-1所示： 代码清单7-1 NeedTest注解类 1234567891011package com.baobaotao.aspectj.anno; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; @Retention(RetentionPolicy.RUNTIME) //①声明注解的保留期限 @Target(ElementType.METHOD)//②声明可以使用该注解的目标类型 public @interface NeedTest &#123;//③定义注解 boolean value() default true;//④声明注解成员 &#125; Java新语法规定使用@interface修饰符定义注解类，如③所示，一个注解可以拥有多个成员，成员声明和接口方法声明类似，这里，我们仅定义了一个成员，如④所示。成员的声明有以下几点限制： 成员以无入参无抛出异常的方式声明，如boolean value(String str)、boolean value() throws Exception等方式是非法的；可以通过default为成员指定一个默认值，如String level() default “LOW_LEVEL”、int high() default 2是合法的，当然也可以不指定默认值；成员类型是受限的，合法的类型包括原始类型及其封装类、String、Class、enums、注解类型，以及上述类型的数组类型。如ForumService value()、List foo()是非法的。 在①和②处，我们所看到的注解是Java预定义的注解，称为元注解（Meta-Annotation），它们被Java编译器使用，会对注解类的行为产生影响。@Retention(RetentionPolicy. RUNTIME)表示NeedTest这个注解可以在运行期被JVM读取，注解的保留期限类型在java.lang.annotation.Retention类中定义，介绍如下： SOURCE：注解信息仅保留在目标类代码的源码文件中，但对应的字节码文件将不再保留；CLASS：注解信息将进入目标类代码的字节码文件中，但类加载器加载字节码文件时不会将注解加载到JVM中，也即运行期不能获取注解信息；RUNTIME：注解信息在目标类加载到JVM后依然保留，在运行期可以通过反射机制读取类中注解信息。Target(ElementType.METHOD)表示NeedTest这个注解只能应用到目标类的方法上，注解的应用目标在java.lang.annotation.ElementType类中定义：TYPE：类、接口、注解类、Enum声明处，相应的注解称为类型注解；FIELD：类成员变量或常量声明处，相应的注解称为域值注解；METHOD：方法声明处，相应的注解称为方法注解；PARAMETER：参数声明处，相应的注解称为参数注解；CONSTRUCTOR：构造函数声明处，相应的注解称为构造函数注解；LOCAL_VARIABLE：局部变量声明处，相应的注解称为局域变量注解；ANNOTATION_TYPE：注解类声明处，相应的注解称为注解类注解，ElementType. TYPE包括ElementType.ANNOTATION_TYPE；PACKAGE：包声明处，相应的注解称为包注解。 如果注解只有一个成员，则成员名必须取名为value()，在使用时可以忽略成员名和赋值号（=），如@NeedTest(true)。注解类拥有多个成员时，如果仅对value成员进行赋值则也可不使用赋值号，如果同时对多个成员进行赋值，则必须使用赋值号，如DeclareParents (value = “NaiveWaiter”, defaultImpl = SmartSeller.class)。注解类可以没有成员，没有成员的注解称为标识注解，解释程序以标识注解存在与否进行相应的处理；此外，所有的注解类都隐式继承于java.lang.annotation.Annotation，但注解不允许显式继承于其他的接口。 我们希望使用NeedTest注解对业务类的方法进行标注，以便测试工具可以根据注解情况激活或关闭对业务类的测试。在编写好NeedTest注解类后，就可以在其他类中使用它了。 使用注解我们在ForumService中使用NeedTest注解，标注业务方法是否需要测试，如代码清单7-2所示： 代码清单7-2 ForumService：使用注解1234567891011package com.baobaotao.aspectj.anno; public class ForumService &#123; @NeedTest(value=true) ① public void deleteForum(int forumId)&#123; System.out.println("删除论坛模块："+forumId); &#125; @NeedTest(value=false) ② public void deleteTopic(int postId)&#123; System.out.println("删除论坛主题："+postId); &#125; &#125; 如果注解类和目标类不在同一个包中，需要通过import引用的注解类。在①和②处，我们使用NeedTest分别对deleteForum()和deleteTopic()方法进行标注。在标注注解时，可以通过以下格式对注解成员进行赋值： &lt;注解名&gt;(&lt;成员名1&gt;=&lt;成员值1&gt;,&lt;成员名1&gt;=&lt;成员值1&gt;,…) 如果成员是数组类型，可以通过{}进行赋值，如boolean数组的成员可以设置为{true,false,true}。下面是几个注解标注的例子： 示例1，多成员的注解：12@AnnoExample(id= 2868724, synopsis = "Enable time-travel", engineer = "Mr. Peabody",date = "4/1/2007") 示例2，一个成员的注解，成员名为value。可以省略成员名和赋值符号： 1@Copyright("2011 bookegou.com All Right Reserved") 示例3，无成员的注解：1@Override 示例4，成员为字符串数组的注解：1@SuppressWarnings(value=&#123;"unchecked","fallthrough"&#125;) 示例5，成员为注解数组类型的注解：12@Reviews(&#123;@Review(grade=Review.Grade.EXCELLENT,reviewer="df"), @Review(grade=Review.Grade.UNSATISFACTORY,reviewer="eg", comment="This method needs an @Override annotation")&#125;) Reviews注解拥有一个@Review注解数组类型的成员，@Review注解类型有三个成员，其中reviewer、comment都是String类型，但comment有默认值，grade是枚举类型的成员。由于NeedTest注解的保留限期是RetentionPolicy.RUNTIME类型，因此当ForumService被加载到JVM时，仍就可通过反射机制访问到ForumService各方法的注解信息。 访问注解前面提到过，注解不会直接影响程序的运行，但是第三方程序或工具可以利用代码中的注解完成特殊的任务，间接控制程序的运行。对于RetentionPolicy.RUNTIME保留期限的注解，我们可以通过反射机制访问类中的注解。 在JDK5.0里，Package、Class、Constructor、Method以及Field等反射对象都新增了访问注解信息的方法：T getAnnotation(Class annotationClass)，该方法支持通过泛型直接返回注解对象。 下面，我们就通过反射来访问注解，得出ForumService 类中通过@NeedTest注解所承载的测试需求，如代码清单7-3所示： 代码清单7-3 TestTool：访问代码中的注解1234567891011121314151617181920212223242526package com.baobaotao.aspectj.anno; import java.lang.reflect.Method; public class TestTool &#123; public static void main(String[] args) &#123; //①得到ForumService对应的Class对象 Class clazz = ForumService.class; //②得到ForumSerivce对应的Method数组 Method[] methods = clazz.getDeclaredMethods(); System.out.println(methods.length); for (Method method : methods) &#123; //③获取方法上所标注的注解对象 NeedTest nt = method.getAnnotation(NeedTest. class); if (nt != null) &#123; if (nt.value()) &#123; System.out.println(method.getName() + "()需要测试"); &#125; else &#123; System.out.println(method.getName() + "()不需要测试"); &#125; &#125; &#125; &#125; &#125; 在③处，通过方法的反射对象，我们获取了方法上所标注的NeedTest注解对象，接着就可以访问注解对象的成员，从而得到ForumService类方法的测试需求。运行以上代码，输出以下的信息： deleteForum()需要测试 deleteTopic()不需要测试]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[【转】Java代理简介]]></title>
      <url>%2Fpost%2Fjava-proxy-introduction%2F</url>
      <content type="text"><![CDATA[spring AOP使用动态代理技术在运行期织入增强的代码，为了揭示Spring AOP底层的工作机理，有必要对涉及到的Java知识进行学习。Spring AOP使用了两种代理机制：一种是基于JDK的动态代理；另一种是基于CGLib的动态代理。之所以需要两种代理机制，很大程度上是因为JDK本身只提供接口的代理，而不支持类的代理。 http://www.iteye.com/topic/1123293 带有横切逻辑的实例我们通过具体化代码实现上一节所介绍例子的性能监视横切逻辑，并通过动态代理技术对此进行改造。在调用每一个目标类方法时启动方法的性能监视，在目标类方法调用完成时记录方法的花费时间。 代码清单 ForumService.java和ForumServiceImpl.java：包含性能监视横切代码 123456789package proxyTest;public interface ForumService &#123; void removeForum(int i); void removeTopic(int i);&#125; 12345678910111213141516171819202122232425262728293031323334package proxyTest;public class ForumServiceImpl implements ForumService &#123; public void removeTopic(int topicId) &#123; // ①-1开始对该方法进行性能监视 PerformanceMonitor.begin("ForumServiceImpl. removeTopic"); System.out.println("模拟删除Topic记录:" + topicId); try &#123; Thread.currentThread(); Thread.sleep(20); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; // ①-2结束对该方法进行性能监视 PerformanceMonitor.end(); &#125; public void removeForum(int forumId) &#123; // ②-1开始对该方法进行性能监视 PerformanceMonitor.begin("ForumServiceImpl. removeForum"); System.out.println("模拟删除Forum记录:" + forumId); try &#123; Thread.currentThread(); Thread.sleep(40); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; // ②-2结束对该方法进行性能监视 PerformanceMonitor.end(); &#125;&#125; 代码清单中粗体表示的代码就是具有横切逻辑特征的代码，每个Service类和每个业务方法体的前后都执行相同的代码逻辑：方法调用前启动PerformanceMonitor，方法调用后通知PerformanceMonitor结束性能监视并给记录性能监视结果。 PerformanceMonitor是性能监视的实现类，我们给出一个非常简单的实现版本，其代码如代码清单所示： 代码清单 PerformanceMonitor.java12345678910111213141516171819202122package proxyTest;public class PerformanceMonitor &#123; //①通过一个ThreadLocal保存调用线程相关的性能监视信息 private static ThreadLocal&lt;MethodPerformance&gt; performanceRecord = new ThreadLocal&lt;MethodPerformance&gt;(); //②启动对某一目标方法的性能监视 public static void begin(String method) &#123; System.out.println("begin monitor..."); MethodPerformance mp = new MethodPerformance(method); performanceRecord.set(mp); &#125; public static void end() &#123; System.out.println("end monitor..."); MethodPerformance mp = performanceRecord.get(); //③打印出方法性能监视的结果信息。 mp.printPerformance(); &#125; &#125; ThreadLocal是将非线程安全类改造为线程安全类的法宝，在9.2节中我们将详细介绍这个Java基础知识。PerformanceMonitor提供了两个方法：通过调用begin(String method)方法开始对某个目标类方法的监视，method为目标类方法的全限定名；而end()方法结束对目标类方法的监视，并给出性能监视的信息。这两个方法必须配套使用。 用于记录性能监视信息的MethodPerformance类的代码如所示： 代码清单 MethodPerformance.java123456789101112131415161718192021222324package proxyTest;public class MethodPerformance &#123; private long begin; private long end; private String serviceMethod; public MethodPerformance(String serviceMethod)&#123; this.serviceMethod = serviceMethod; //①记录目标类方法开始执行点的系统时间 this.begin = System.currentTimeMillis(); &#125; public void printPerformance()&#123; //②获取目标类方法执行完成后的系统时间，并进而计算出目标类方法执行时间 end = System.currentTimeMillis(); long elapse = end - begin; //③报告目标类方法的执行时间 System.out.println(serviceMethod+"花费"+elapse+"毫秒。"); &#125; &#125; 通过下面的代码测试拥有性能监视能力的ForumServiceImpl业务方法：12345678910package proxyTest;public class TestForumService &#123; public static void main(String[] args) &#123; ForumService forumService = new ForumServiceImpl(); forumService.removeForum(10); forumService.removeTopic(1012); &#125;&#125; 我们得到以下输出信息： begin monitor… ①removeForum(10)方法的性能监视报告模拟删除Forum记录:10end monitor…com.baobaotao.proxy.ForumServiceImpl.removeForum花费47毫秒。begin monitor… ①removeTopic(1012)方法的性能监视报告模拟删除Topic记录:1012end monitor…com.baobaotao.proxy.ForumServiceImpl.removeTopic花费26毫秒。 正如代码清单实例所示，当某个方法需要进行性能监视，就必须调整方法代码，在方法体前后分别添加上开启性能监视和结束性能监视的代码。这些非业务逻辑的性能监视代码破坏了ForumServiceImpl业务逻辑的纯粹性。我们希望通过代理的方式，将业务类方法中开启和结束性能监视的这些横切代码从业务类中完全移除。并通过JDK动态代理技术或CGLib动态代理技术将横切代码动态织入到目标方法的相应位置。 JDK动态代理JDK 1.3以后，Java提供了动态代理的技术，允许开发者在运行期创建接口的代理实例。在Sun刚推出动态代理时，还很难想象它有多大的实际用途，现在我们终于发现动态代理是实现AOP的绝好底层技术。 JDK的动态代理主要涉及到java.lang.reflect包中的两个类：Proxy和InvocationHandler。其中InvocationHandler是一个接口，可以通过实现该接口定义横切逻辑，并通过反射机制调用目标类的代码，动态将横切逻辑和业务逻辑编织在一起。 而Proxy利用InvocationHandler动态创建一个符合某一接口的实例，生成目标类的代理对象。这样讲一定很抽象，我们马上着手使用Proxy和InvocationHandler这两个魔法戒对上一节中的性能监视代码进行革新。 首先，我们从业务类ForumServiceImpl中删除性能监视的横切代码，使ForumServiceImpl只负责具体的业务逻辑，如代码清单6-5所示： 代码清单6-5 ForumServiceImpl：移除性能监视横切代码 1234567891011121314151617181920212223242526package proxyTest;public class ForumServiceImpl implements ForumService &#123; public void removeTopic(int topicId) &#123; System.out.println("模拟删除Topic记录:" + topicId); try &#123; Thread.currentThread(); Thread.sleep(20); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; public void removeForum(int forumId) &#123; System.out.println("模拟删除Forum记录:" + forumId); try &#123; Thread.currentThread(); Thread.sleep(40); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125;&#125; 在代码清单中的①和②处，原来的性能监视代码被移除了，我们只保留了真正的业务逻辑。 从业务类中移除的性能监视横切代码当然不能漂浮在空气中，它还得找到一个安身之所，InvocationHandler就是横切代码的安家乐园，我们将性能监视的代码安置在PerformanceHandler中，如代码清单所示： 123456789101112131415161718package proxyTest;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;public class PerformanceHandler implements InvocationHandler &#123; private Object target; public PerformanceHandler(Object target) &#123; // ②target为目标的业务类 this.target = target; &#125; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; PerformanceMonitor.begin(target.getClass().getName() + "." + method.getName()); Object obj = method.invoke(target, args);// ③-2通过反射方法调用业务类的目标方法 PerformanceMonitor.end(); return obj; &#125;&#125; ③处invoke()方法中粗体所示部分的代码为性能监视的横切代码，我们发现，横切代码只出现一次，而不是原来那样星洒各处。③-2处的method.invoke()语句通过Java反射机制间接调用目标对象的方法，这样InvocationHandler的invoke()方法就将横切逻辑代码（③-1）和业务类方法的业务逻辑代码（③-2）编织到一起了，所以我们可以将InvocationHandler看成是一个编织器。下面，我们对这段代码做进一步的说明。 首先，我们实现InvocationHandler接口，该接口定义了一个 invoke(Object proxy, Method method, Object[] args)的方法，proxy是最终生成的代理实例，一般不会用到；method是被代理目标实例的某个具体方法，通过它可以发起目标实例方法的反射调用；args是通过被代理实例某一个方法的入参，在方法反射调用时使用。 此外，我们在构造函数里通过target传入希望被代理的目标对象，如②处所示，在InvocationHandler接口方法invoke(Object proxy, Method method, Object[] args)里，将目标实例传给method.invoke()方法，调用目标实例的方法，如③所示。下面，我们通过Proxy结合PerformanceHandler创建ForumService接口的代理实例，如代码清单所示：代码清单 TestForumService：创建代理实例1234567891011121314151617181920212223package proxyTest;import java.lang.reflect.Proxy;public class TestForumService &#123; public static void main(String[] args) &#123; // ①希望被代理的目标业务类 ForumService target = new ForumServiceImpl(); // ②将目标业务类和横切代码编织到一起 PerformanceHandler handler = new PerformanceHandler(target); // ③根据编织了目标业务类逻辑和性能监视横切逻辑的InvocationHandler实例创建代理实例 ForumService proxy = (ForumService) Proxy.newProxyInstance(target .getClass().getClassLoader(), target.getClass().getInterfaces(), handler); // ④调用代理实例 proxy.removeForum(10); proxy.removeTopic(1012); &#125;&#125; 上面的代码完成业务类代码和横切代码的编织工作并生成了代理实例。在②处，我们让PerformanceHandler将性能监视横切逻辑编织到ForumService实例中，然后在③处，通过Proxy的newProxyInstance()静态方法为编织了业务类逻辑和性能监视逻辑的handler创建一个符合ForumService接口的代理实例。该方法的第一个入参为类加载器；第二个入参为创建代理实例所需要实现的一组接口；第三个参数是整合了业务逻辑和横切逻辑的编织器对象。 按照③处的设置方式，这个代理实例实现了目标业务类的所有接口，即Forum ServiceImpl的ForumService接口。这样，我们就可以按照调用ForumService接口实例相同的方式调用代理实例，如④所示。运行以上的代码，输出以下信息： begin monitor…模拟删除Forum记录:10end monitor…com.baobaotao.proxy.ForumServiceImpl.removeForum花费47毫秒。begin monitor…模拟删除Topic记录:1012end monitor…com.baobaotao.proxy.ForumServiceImpl.removeTopic花费26毫秒。 我们发现，程序的运行效果和直接在业务类中编写性能监视逻辑的效果一致，但是在这里，原来分散的横切逻辑代码已经被我们抽取到PerformanceHandler中。当其他业务类（如UserService、SystemService等）的业务方法也需要使用性能监视时，我们只要按照代码清单6-7相似的方式，分别为它们创建代理对象就可以了。下面，我们通过时序图描述通过创建代理对象进行业务方法调用的整体逻辑，以进一步认识代理对象的本质，如图所示。 我们在上图中使用虚线的方式对通过Proxy创建的ForumService代理实例加以凸显，ForumService代理实例内部利用PerformaceHandler整合横切逻辑和业务逻辑。调用者调用代理对象的removeForum()和removeTopic()方法时，上图的内部调用时序清晰地告诉我们实际上所发生的一切。 CGLib动态代理使用JDK创建代理有一个限制，即它只能为接口创建代理实例，这一点我们可从Proxy的接口newProxyInstance(ClassLoader loader, Class[] interfaces, InvocationHandler h)的方法签名中就看得很清楚：第二个入参interfaces就是需要代理实例实现的接口列表。虽然面向接口编程的思想被很多大师级人物（包括Rod Johnson）推崇，但在实际开发中，许多开发者也对此深感困惑：难道对一个简单业务表的操作也需要老老实实地创建5个类（领域对象类、Dao接口，Dao实现类，Service接口和Service实现类）吗？难道不能直接通过实现类构建程序吗？对于这个问题，我们很难给出一个孰好孰劣的准确判断，但我们确实发现有很多不使用接口的项目也取得了非常好的效果（包括大家所熟悉的SpringSide开源项目）。 对于没有通过接口定义业务方法的类，如何动态创建代理实例呢？JDK的代理技术显然已经黔驴技穷，CGLib作为一个替代者，填补了这个空缺。 CGLib采用非常底层的字节码技术，可以为一个类创建子类，并在子类中采用方法拦截的技术拦截所有父类方法的调用，并顺势织入横切逻辑。下面，我们采用CGLib技术，编写一个可以为任何类创建织入性能监视横切逻辑代理对象的代理创建器，如代码清单 所示： 代码清单 CglibProxy1234567891011121314151617181920212223242526package proxyTest;import java.lang.reflect.Method;import net.sf.cglib.proxy.Enhancer;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;public class CglibProxy implements MethodInterceptor &#123; private Enhancer enhancer = new Enhancer(); public Object getProxy(@SuppressWarnings("rawtypes") Class clazz) &#123; enhancer.setSuperclass(clazz); // ① 设置需要创建子类的类 enhancer.setCallback(this); return enhancer.create(); // ②通过字节码技术动态创建子类实例 &#125; // ③拦截父类所有方法的调用 public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; PerformanceMonitor.begin(obj.getClass().getName() + "." + method.getName());// ③-1 Object result = proxy.invokeSuper(obj, args); PerformanceMonitor.end();// ③-1通过代理类调用父类中的方法 return result; &#125;&#125; 在上面代码中，用户可以通过getProxy(Class clazz)为一个类创建动态代理对象，该代理对象通过扩展clazz创建代理对象。在这个代理对象中，我们织入性能监视的横切逻辑（③-1）。intercept(Object obj, Method method, Object[] args,MethodProxy proxy)是CGLib定义的Interceptor接口的方法，它拦截所有目标类方法的调用，obj表示目标类的实例；method为目标类方法的反射对象；args为方法的动态入参；而proxy为代理类实例。 下面，我们通过CglibProxy为ForumServiceImpl类创建代理对象，并测试代理对象的方法，如代码清单所示： 代码清单 TestForumService：测试Cglib创建的代理类 小结Spring AOP的底层就是通过使用JDK动态代理或CGLib动态代理技术为目标Bean织入横切逻辑。在这里，我们对前面两节动态创建代理对象作一个小结。 我们虽然通过PerformanceHandler或CglibProxy实现了性能监视横切逻辑的动态织入，但这种实现方式存在三个明显需要改进的地方： 1）目标类的所有方法都添加了性能监视横切逻辑，而有时，这并不是我们所期望的，我们可能只希望对业务类中的某些特定方法添加横切逻辑；2）我们通过硬编码的方式指定了织入横切逻辑的织入点，即在目标类业务方法的开始和结束前织入代码；3）我们手工编写代理实例的创建过程，为不同类创建代理时，需要分别编写相应的创建代码，无法做到通用。 以上三个问题，在AOP中占用重要的地位，因为Spring AOP的主要工作就是围绕以上三点展开：Spring AOP通过Pointcut（切点）指定在哪些类的哪些方法上织入横切逻辑，通过Advice（增强）描述横切逻辑和方法的具体织入点（方法前、方法后、方法的两端等）。此外，Spring通过Advisor（切面）将Pointcut和Advice两者组装起来。有了Advisor的信息，Spring就可以利用JDK或CGLib的动态代理技术采用统一的方式为目标Bean创建织入切面的代理对象了。 JDK动态代理所创建的代理对象，在JDK 1.3下，性能强差人意。虽然在高版本的JDK中，动态代理对象的性能得到了很大的提高，但是有研究表明，CGLib所创建的动态代理对象的性能依旧比JDK的所创建的代理对象的性能高不少（大概10倍）。但CGLib在创建代理对象时所花费的时间却比JDK动态代理多（大概8倍），所以对于singleton的代理对象或者具有实例池的代理，因为无须频繁创建代理对象，所以比较适合用CGLib动态代理技术，反之适合用JDK动态代理技术。值得一提的是，由于CGLib采用动态创建子类的方式生成代理对象，所以不能对目标类中的final方法进行代理。 begin monitor…模拟删除Forum记录:10end monitor…com.baobaotao.proxy.ForumServiceImpl$EnhancerByCGLIB$$2a9199c0.removeForum花费47毫秒。begin monitor…模拟删除Topic记录:1023end monitor…com.baobaotao.proxy.ForumServiceImpl$EnhancerByCGLIB$$2a9199c0.removeTopic花费16毫秒。 观察以上的输出，除了发现两个业务方法中都织入了性能监控的逻辑外，我们还发现代理类的名字是com.baobaotao.proxy.ForumServiceImpl$EnhancerByCGLIB2a9199c0，这个特殊的类就是CGLib为ForumServiceImpl动态创建的子类。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[【转】Java反射简介]]></title>
      <url>%2Fpost%2Fjava-reflection-introduction%2F</url>
      <content type="text"><![CDATA[Java语言允许通过程序化的方式间接对Class进行操作，Class文件由类装载器装载后，在JVM中将形成一份描述Class结构的元信息对象，通过该元信息对象可以获知Class的结构信息：如构造函数、属性和方法等。Java允许用户借由这个Class相关的元信息对象间接调用Class对象的功能，这就为使用程序化方式操作Class对象开辟了途径。 原文链接：http://stamen.iteye.com/blog/1497981 简单实例我们将从一个简单例子开始探访Java反射机制的征程，下面的Car类拥有两个构造函数、两个方法以及三个属性 代码清单 Car.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647ublic class Car &#123; private String brand; private String color; private int maxSpeed; // ①默认构造函数 public Car() &#123; &#125; // ②带参构造函数 public Car(String brand, String color, int maxSpeed) &#123; this.brand = brand; this.color = color; this.maxSpeed = maxSpeed; &#125; // ③未带参的方法 public void introduce() &#123; System.out.println("brand:" + brand + ";color:" + color + ";maxSpeed:" + maxSpeed); &#125; public String getBrand() &#123; return brand; &#125; public void setBrand(String brand) &#123; this.brand = brand; &#125; public String getColor() &#123; return color; &#125; public void setColor(String color) &#123; this.color = color; &#125; public int getMaxSpeed() &#123; return maxSpeed; &#125; public void setMaxSpeed(int maxSpeed) &#123; this.maxSpeed = maxSpeed; &#125;&#125; 一般情况下，我们会使用如下的代码创建Car的实例： 12Car car = new Car(); car.setBrand("红旗CA72"); 或者1Car car = new Car("红旗CA72","黑色"); 以上两种方法都采用传统方式的直接调用目标类的方法，下面我们通过Java反射机制以一种更加通用的方式间接地操作目标类： 代码清单：ReflectTest.java1234567891011121314151617181920212223242526272829import java.lang.reflect.Constructor;import java.lang.reflect.Field;import java.lang.reflect.Method;public class ReflectTest &#123; public static Car initByDefaultConst() throws Throwable &#123; // ①通过类装载器获取Car类对象 ClassLoader loader = Thread.currentThread().getContextClassLoader(); Class clazz = loader.loadClass("Car"); // ②获取类的默认构造器对象并通过它实例化Car Constructor cons = clazz.getDeclaredConstructor((Class[]) null); Car car = (Car) cons.newInstance(); // ③通过反射方法设置属性 Method setBrand = clazz.getMethod("setBrand", String.class); setBrand.invoke(car, "红旗CA72"); Method setColor = clazz.getMethod("setColor", String.class); setColor.invoke(car, "黑色"); Method setMaxSpeed = clazz.getMethod("setMaxSpeed", int.class); setMaxSpeed.invoke(car, 200); return car; &#125; public static void main(String[] args) throws Throwable &#123; Car car = initByDefaultConst(); car.introduce(); &#125;&#125; 运行以上程序，在控制台上将打印出以下信息： brand:红旗CA72;color:黑色;maxSpeed:200 这说明我们完全可以通过编程方式调用Class的各项功能，这和直接通过构造函数和方法调用类功能的效果是一致的，只不过前者是间接调用，后者是直接调用罢了。 在ReflectTest中，使用了几个重要的反射类，分别是ClassLoader、Class、Constructor和Method，通过这些反射类就可以间接调用目标Class的各项功能了。在①处，我们获取当前线程的ClassLoader，然后通过指定的全限定类“com.baobaotao.beans.Car”装载Car类对应的反射实例。在②处，我们通过Car的反射类对象获取Car的构造函数对象cons，通过构造函数对象的newInstrance()方法实例化Car对象，其效果等同于new Car()。在③处，我们又通过Car的反射类对象的getMethod（String methodName,Class paramClass）获取属性的Setter方法对象，第一个参数是目标Class的方法名；第二个参数是方法入参的对象类型。获取方法反射对象后，即可通过invoke（Object obj,Object param）方法调用目标类的方法，该方法的第一个参数是操作的目标类对象实例；第二个参数是目标方法的入参。 在代码清单3 10中，粗体所示部分的信息即是通过反射方法操控目标类的元信息，如果我们将这些信息以一个配置文件的方式提供，就可以使用Java语言的反射功能编写一段通用的代码对类似于Car的类进行实例化及功能调用操作了。 类装载器ClassLoader类装载器工作机制类装载器就是寻找类的节码文件并构造出类在JVM内部表示对象的组件。在Java中，类装载器把一个类装入JVM中，要经过以下步骤： [1.]装载：查找和导入Class文件；[2.]链接：执行校验、准备和解析步骤，其中解析步骤是可以选择的：[2.1]校验：检查载入Class文件数据的正确性；[2.2]准备：给类的静态变量分配存储空间；[2.3]解析：将符号引用转成直接引用；[3.]初始化：对类的静态变量、静态代码块执行初始化工作。 类装载工作由ClassLoader及其子类负责，ClassLoader是一个重要的Java运行时系统组件，它负责在运行时查找和装入Class字节码文件。JVM在运行时会产生三个ClassLoader：根装载器、ExtClassLoader（扩展类装载器）和AppClassLoader（系统类装载器）。其中，根装载器不是ClassLoader的子类，它使用C++编写，因此我们在Java中看不到它，根装载器负责装载JRE的核心类库，如JRE目标下的rt.jar、charsets.jar等。ExtClassLoader和AppClassLoader都是ClassLoader的子类。其中ExtClassLoader负责装载JRE扩展目录ext中的JAR类包；AppClassLoader负责装载Classpath路径下的类包。 这三个类装载器之间存在父子层级关系，即根装载器是ExtClassLoader的父装载器，ExtClassLoader是AppClassLoader的父装载器。默认情况下，使用AppClassLoader装载应用程序的类，我们可以做一个实验： 代码清单: ClassLoaderTest.java123456789public class ClassLoaderTest &#123; public static void main(String[] args) &#123; ClassLoader loader = Thread.currentThread().getContextClassLoader(); System.out.println("current loader:" + loader); System.out.println("parent loader:" + loader.getParent()); System.out.println("grandparent loader:" + loader.getParent().getParent()); &#125;&#125; 运行以上代码，在控制台上将打出以下信息： current loader:sun.misc.Launcher$AppClassLoader@131f71aparent loader:sun.misc.Launcher$ExtClassLoader@15601ea //①根装载器在Java中访问不到，所以返回nullgrandparent loader:null 通过以上的输出信息，我们知道当前的ClassLoader是AppClassLoader，父ClassLoader是ExtClassLoader，祖父ClassLoader是根类装载器，因为在Java中无法获得它的句柄，所以仅返回null。 JVM装载类时使用“全盘负责委托机制”，“全盘负责”是指当一个ClassLoader装载一个类的时，除非显式地使用另一个ClassLoader，该类所依赖及引用的类也由这个ClassLoader载入；“委托机制”是指先委托父装载器寻找目标类，只有在找不到的情况下才从自己的类路径中查找并装载目标类。这一点是从安全角度考虑的，试想如果有人编写了一个恶意的基础类（如java.lang.String）并装载到JVM中将会引起多么可怕的后果。但是由于有了“全盘负责委托机制”，java.lang.String永远是由根装载器来装载的，这样就避免了上述事件的发生。 ClassLoader重要方法在Java中，ClassLoader是一个抽象类，位于java.lang包中。下面对该类的一些重要接口方法进行介绍：Class loadClass(String name)name参数指定类装载器需要装载类的名字，必须使用全限定类名，如com.baobaotao. beans.Car。该方法有一个重载方法loadClass(String name ,boolean resolve)，resolve参数告诉类装载器是否需要解析该类。在初始化类之前，应考虑进行类解析的工作，但并不是所有的类都需要解析，如果JVM只需要知道该类是否存在或找出该类的超类，那么就不需要进行解析。 Class defineClass(String name, byte[] b, int off, int len)将类文件的字节数组转换成JVM内部的java.lang.Class对象。字节数组可以从本地文件系统、远程网络获取。name为字节数组对应的全限定类名。 Class findSystemClass(String name)从本地文件系统载入Class文件，如果本地文件系统不存在该Class文件，将抛出ClassNotFoundException异常。该方法是JVM默认使用的装载机制。Class findLoadedClass(String name)调用该方法来查看ClassLoader是否已装入某个类。如果已装入，那么返回java.lang.Class对象，否则返回null。如果强行装载已存在的类，将会抛出链接错误。 ClassLoader getParent()获取类装载器的父装载器，除根装载器外，所有的类装载器都有且仅有一个父装载器，ExtClassLoader的父装载器是根装载器，因为根装载器非Java编写，所以无法获得，将返回null。 除JVM默认的三个ClassLoader以外，可以编写自己的第三方类装载器，以实现一些特殊的需求。类文件被装载并解析后，在JVM内将拥有一个对应的java.lang.Class类描述对象，该类的实例都拥有指向这个类描述对象的引用，而类描述对象又拥有指向关联ClassLoader的引用，如图3所示。 每一个类在JVM中都拥有一个对应的java.lang.Class对象，它提供了类结构信息的描述。数组、枚举、注解以及基本Java类型（如int、double等），甚至void都拥有对应的Class对象。Class没有public的构造方法。Class对象是在装载类时由JVM通过调用类装载器中的defineClass()方法自动构造的。 Java反射机制Class反射对象描述类语义结构，可以从Class对象中获取构造函数、成员变量、方法类等类元素的反射对象，并以编程的方式通过这些反射对象对目标类对象进行操作。这些反射对象类在java.reflect包中定义，下面是最主要的三个反射类： Constructor：类的构造函数反射类，通过Class#getConstructors()方法可以获得类的所有构造函数反射对象数组。在JDK5.0中，还可以通过getConstructor(Class… parameterTypes)获取拥有特定入参的构造函数反射对象。Constructor的一个主要方法是newInstance(Object[] initargs)，通过该方法可以创建一个对象类的实例，相当于new关键字。在JDK5.0中该方法演化为更为灵活的形式：newInstance (Object… initargs)。 Method：类方法的反射类，通过Class#getDeclaredMethods()方法可以获取类的所有方法反射类对象数组Method[]。在JDK5.0中可以通过getDeclaredMethod(String name, Class… parameterTypes)获取特定签名的方法，name为方法名；Class…为方法入参类型列表。Method最主要的方法是invoke(Object obj, Object[] args)，obj表示操作的目标对象；args为方法入参，代码清单3 10③处演示了这个反射类的使用方法。在JDK 5.0中，该方法的形式调整为invoke(Object obj, Object… args)。此外，Method还有很多用于获取类方法更多信息的方法：1）Class getReturnType()：获取方法的返回值类型；2）Class[] getParameterTypes()：获取方法的入参类型数组；3）Class[] getExceptionTypes()：获取方法的异常类型数组；4）Annotation[][] getParameterAnnotations()：获取方法的注解信息，JDK 5.0中的新方法； Field：类的成员变量的反射类，通过Class#getDeclaredFields()方法可以获取类的成员变量反射对象数组，通过Class#getDeclaredField(String name)则可获取某个特定名称的成员变量反射对象。Field类最主要的方法是set(Object obj, Object value)，obj表示操作的目标对象，通过value为目标对象的成员变量设置值。如果成员变量为基础类型，用户可以使用Field类中提供的带类型名的值设置方法，如setBoolean(Object obj, boolean value)、setInt(Object obj, int value)等。 此外，Java还为包提供了Package反射类，在JDK 5.0中还为注解提供了AnnotatedElement反射类。总之，Java的反射体系保证了可以通过程序化的方式访问目标类中所有的元素，对于private或protected的成员变量和方法，只要JVM的安全机制允许，也可以通过反射进行调用，请看下面的例子： 代码清单 PrivateCar.java 12345678910111213141516171819202122import java.lang.reflect.Field;import java.lang.reflect.Method;public class PrivateCarReflect &#123; public static void main(String[] args) throws Throwable &#123; ClassLoader loader = Thread.currentThread().getContextClassLoader(); Class clazz = loader.loadClass("PrivateCar"); PrivateCar pcar = (PrivateCar) clazz.newInstance(); Field colorFld = clazz.getDeclaredField("color"); // ①取消Java语言访问检查以访问private变量 colorFld.setAccessible(true); colorFld.set(pcar, "红色"); Method driveMtd = clazz.getDeclaredMethod("drive", (Class[]) null); // Method driveMtd = clazz.getDeclaredMethod("drive"); JDK5.0下使用 // ②取消Java语言访问检查以访问protected方法 driveMtd.setAccessible(true); driveMtd.invoke(pcar, (Object[]) null); &#125;&#125; 运行该类，打印出以下信息： drive private car! the color is:红色 在访问private、protected成员变量和方法时必须通过setAccessible(boolean access)方法取消Java语言检查，否则将抛出IllegalAccessException。如果JVM的安全管理器设置了相应的安全机制，调用该方法将抛出SecurityException。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[《像程序员一样思考》读书笔记]]></title>
      <url>%2Fpost%2Fthink-like-programmer-readnote%2F</url>
      <content type="text"><![CDATA[这本书的第一章阐述了一些解决问题的策略，举了几个例子，还是挺有趣的，之后还用c++演示了一些具体的解决问题的方法，有兴趣可以读一下 认识到一个已解决的问题和一个未解决的问题之间可供利用的相似之处。如果我们发现问题A的一个特性与已经解决的问题B的一个特性有相似之处，就为解决A奠定了良好的基础。 用更形象化的方式重新陈述问题是一种非常出色的技巧，可以让我们拥有对问题更好的洞察力。许多程序员设法与其他程序员一起讨论问题，并不仅仅是因为对方可能已经有了答案，而是因为清晰的陈述问题常常会激发有用的新思路。重新陈述问题就相当于与其他程序员讨论问题，只不过现在一个人分饰两角。 在解决编程问题时，有时会出现无法看到通向解决方案的清晰道路的情况，但这决不能成为跳过计划和采用系统性方法的借口。更好的办法是采用一种策略，而不是通过简单地反复尝试和失败来解决问题。 在面临一个复杂的问题时，我常常会对这个问题的削减版本进行试验。这些试验常常能够产生有价值的思路。花时间研究怎样对问题进行细分通常是非常合算的，即使无法找到一种清晰的细分，仍然有助于增强对问题的理解，可以促进这个问题的解决。在解决问题时，头脑里已经有一个特点的目标总比随机的尝试要好得多，无论最终是否能够实现这个目标。 应该从最显而易见的那部分任务开始着手，如果可以解决这个部分的问题，就可以在此基础上继续执行其他可以完成的任务，通过审视自己的代码，可能会激发自己的想象力，从而解决剩余部分的问题。 基本的问题解决技巧： 总是要指定计划这也许是最重要的规则，我们事先必须要制定计划，而不是直接进行漫无方向的尝试。 重新陈述问题即使重新陈述问题并没有直接让我们获得新思路，它仍然可能在其他方面提供帮助。例如，如果我们碰到一个问题（又上级或者指导老师指派），我们可以把问题重新陈述给指派这个任务的人，以确定自己的理解无误，另外，重新重述问题对于使用其他常用的技巧也可能是一个必要的先决步骤，例如削减和划分问题。 划分问题 从自己所知的开始 削减问题 寻找类比 试验 避免陷入挫折感 如果你觉得继续干下去会陷入挫折感时，可以休息一会，一个诀窍是让手头上处理的问题不止一个，这样，如果你对一个问题感到无可奈何，可以把精力转向另一个问题，注意，如果成功的划分了问题，就可以对单个问题应用这种技巧，只要把陷入僵局的那部分问题仍到一边，转而解决其他部分问题就可以了，如果没哟可以处理其他问题，也可以离开椅子做一些其他的事情，可以热热身，放松一下脑子，例如散步。洗衣服。做伸展运动，在休息结束之前。不在考虑那个问题。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Sublime Text 3简介]]></title>
      <url>%2Fpost%2FSublime-introduction%2F</url>
      <content type="text"><![CDATA[sublime 是一款小巧绿色且速度非常快的代码编辑器，下面介绍一下它的安装和插件的使用 安装官方下载地址：http://www.sublimetext.com/3 破解打开sublime_text.exe，help-&gt;enter License附 license： license：—– BEGIN LICENSE —–K-20Single User LicenseEA7E-9401293A099EC1 C0B5C7C5 33EBF0CF BE82FE3BEAC2164A 4F8EC954 4E87F1E5 7E4E85D6C5605DE6 DAB003B4 D60CA4D0 77CB15333C47F579 FB3E8476 EB3AA9A7 68C43CD98C60B563 80FE367D 8CAD14B3 54FB7A9F4123FFC4 D63312BA 141AF702 F6BBA254B094B9C0 FAA4B04C 06CC9AFC FD41267182E3AEE0 0F0FAAA7 8FA773C9 383A9E18—— END LICENSE —— 更多参考：http://www.janecc.com/sublime-text-3-crack-zh-cn.html Sublime text 3 Package ControlSublime text 3 Package Control是sublime安装插件的管理器 安装步骤：http://jingyan.baidu.com/article/c14654134b8bde0bfcfc4c9a.html emmet的前身是大名鼎鼎的Zen coding，如果你从事Web前端开发的话，对该插件一定不会陌生。它使用仿CSS选择器的语法来生成代码，大大提高了HTML/CSS代码编写的速度 安装emmet插件：http://jingyan.baidu.com/article/ca00d56c76d0fae99eebcfdf.html 更多参考：http://www.iteye.com/news/27580 用emmet插件快速新建html文件，可以新建一个html文件 打开，然后输入 html加tab键 更多参考：http://www.cnblogs.com/freeyiyi1993/p/3629905.html 格式化html代码 tag插件 Ctrl+Alt+F对代码进行格式化参考：http://www.5imb.com/show-83-5884-1.html 快捷键：删除一行 ctrl+shift+k 更多快捷键，参考：http://www.jb51.net/softjc/180873.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Swagger简介]]></title>
      <url>%2Fpost%2Fswagger-introduction%2F</url>
      <content type="text"><![CDATA[Swagger 是一款RESTFUL接口的文档在线自动生成+功能测试功能软件。本文简单介绍了在项目中集成swagger的方法和一些常见问题。 如果想深入分析项目源码，了解更多内容，见参考资料。Swagger 是一个规范和完整的框架，用于生成、描述、调用和可视化 RESTful 风格的 Web 服务。总体目标是使客户端和文件系统作为服务器以同样的速度来更新。文件的方法，参数和模型紧密集成到服务器端的代码，允许API来始终保持同步。Swagger 让部署管理和使用功能强大的API从未如此简单。 使用介绍什么是swaggerSwagger™的目标是为REST APIs 定义一个标准的，与语言无关的接口，使人和计算机在看不到源码或者看不到文档或者不能通过网络流量检测的情况下能发现和理解各种服务的功能。当服务通过Swagger定义，消费者就能与远程的服务互动通过少量的实现逻辑。类似于低级编程接口，Swagger去掉了调用服务时的很多猜测。 浏览 Swagger-Spec 去了解更多关于Swagger 项目的信息，包括附加的支持其他语言的库。 如何集成Swagger-springmvc到我们的项目中?Maven12345&lt;dependency&gt; &lt;groupId&gt;com.mangofactory&lt;/groupId&gt; &lt;artifactId&gt;swagger-springmvc&lt;/artifactId&gt; &lt;version&gt;0.9.4&lt;/version&gt;&lt;/dependency&gt; Gradlerepositories { jcenter() } compile &quot;com.mangofactory:swagger-springmvc:0.9.4&quot; 要最快捷地启动swagger-springmvc项目并且使用默认设置，推荐的方式是使用SwaggerSpringMvc插件 Spring Java Configuration1234567@Configuration@EnableWebMvc@EnableSwagger@ComponentScan("com.myapp.packages")public class WebAppConfig &#123; ...&#125; Spring xml Configuration12&lt;mvc:annotation-driven/&gt; &lt;!-- Required so swagger-springmvc can access spring's RequestMappingHandlerMapping --&gt;&lt;bean class="com.mangofactory.swagger.configuration.SpringSwaggerConfig" /&gt; SwaggerSpringMvcPlugin XML Configuration为了使用这个插件，你需要创造一个spring Java配置类。使用spring的 @Configuration ，这个配置类必须被定义到你的xml上下文12&lt;!-- Required so swagger-springmvc can access spring's RequestMappingHandlerMapping --&gt;&lt;mvc:annotation-driven/&gt; 1234567891011121314151617181920212223242526bean class="com.yourapp.configuration.MySwaggerConfig"/&gt;@Configuration@EnableSwagger //Loads the spring beans required by the frameworkpublic class MySwaggerConfig &#123;private SpringSwaggerConfig springSwaggerConfig;/*** Required to autowire SpringSwaggerConfig*/@Autowiredpublic void setSpringSwaggerConfig(SpringSwaggerConfig springSwaggerConfig) &#123; this.springSwaggerConfig = springSwaggerConfig;&#125;/*** Every SwaggerSpringMvcPlugin bean is picked up by the swagger-mvc framework - allowing for multiple* swagger groups i.e. same code base multiple swagger resource listings. */@Beanpublic SwaggerSpringMvcPlugin customImplementation()&#123; return new SwaggerSpringMvcPlugin(this.springSwaggerConfig) .includePatterns(".*pet.*");&#125;&#125; SwaggerSpringMvcPlugin Spring Java Configuration使用@EnableSwagger注解自动注入SpringSwaggerConfig定义一个或多个SwaggerSpringMvcPlugin实例，通过springs @Bean注解 1234567891011121314151617181920212223242526272829303132@Configuration@EnableWebMvc@EnableSwagger@ComponentScan("com.myapp.controllers")public class CustomJavaPluginConfig &#123;private SpringSwaggerConfig springSwaggerConfig;@Autowiredpublic void setSpringSwaggerConfig(SpringSwaggerConfig springSwaggerConfig) &#123; this.springSwaggerConfig = springSwaggerConfig;&#125;@Bean //Don't forget the @Bean annotationpublic SwaggerSpringMvcPlugin customImplementation()&#123; return new SwaggerSpringMvcPlugin(this.springSwaggerConfig) .apiInfo(apiInfo()) .includePatterns(".*pet.*");&#125;private ApiInfo apiInfo() &#123; ApiInfo apiInfo = new ApiInfo( "My Apps API Title", "My Apps API Description", "My Apps API terms of service", "My Apps API Contact Email", "My Apps API Licence Type", "My Apps API License URL" ); return apiInfo;&#125;&#125; 碰到的问题关于@API注解在Swagger Annotation中： API表示一个开放的API，可以通过description简要描述该API的功能。在一个@API下，可有多个@ApiOperation，表示针对该API的CRUD操作。在ApiOperation Annotation中可以通过value，notes描述该操作的作用，response描述正常情况下该请求的返回对象类型。 在一个ApiOperation下，可以通过ApiResponses描述该API操作可能出现的异常情况。 ApiParam用于描述该API操作接受的参数类型再接着，为项目的Model对象添加Swagger Annotation，这样Swagger Scanner可以获取更多关于Model对象的信息。 12345678910111213141516171819@ApiModel(value = "A SayingRepresentation is a representation of greeting")@JsonSerialize(include = JsonSerialize.Inclusion.NON_NULL)public class SayingRepresentation &#123;private long id;@ApiModelProperty(value = "greeting content", required = true)private String content;public SayingRepresentation(long id, String content) &#123; this.id = id; this.content = content;&#125;public long getId() &#123; return id;&#125;public String getContent() &#123; return content;&#125; 通过上面的步骤，项目已经具备了提供Swagger格式的API信息的能力，接下来，我们把这些信息和Swagger UI集成，以非常美观，实用的方式把这些API信息展示出来。 ##和Swagger UI的集成首先，从github(https://github.com/wordnik/swagger-ui)上下载Swagger-UI, 把该项目dist目录下的内容拷贝到项目的resources的目录assets下。 然后，修改index.html, 把Swagger UI对象中的URL替换为自己的API路径。 window.swaggerUi = new SwaggerUi({ url: &quot;/api/api-docs&quot;, dom_id: &quot;swagger-ui-container&quot;, 最后，为了能访问到该页面，还需要在Service的Initialize方法中，添加AssetsBundle 12345public void initialize(Bootstrap&lt;HelloWorldConfiguration&gt; bootstrap) &#123; //指定配置文件的名字 bootstrap.setName("helloWorld"); bootstrap.addBundle(new AssetsBundle("/assets", "/", "index.html"));&#125; 最后的效果图： 评价Swagger可以充当前后端交流的重要桥梁，方便快捷。很实用。 Swagger项目允许你生产，显示和消费你自己的RESTful服务。不需要代理和第三方服务。是一个依赖自由的资源集合，它能通过Swagger API动态的生成漂亮的文档和沙盒,因为Swagger UI没有依赖，你可以把他部署到任何服务器环境或者是你自己的机器。 参考资料官网：http://swagger.io/ GitHub：swagger-springmvc:https://github.com/martypitt/swagger-springmvc swagger-ui:https://github.com/swagger-api/swagger-ui swagger-core:https://github.com/swagger-api/swagger-core swagger-spec：https://github.com/swagger-api/swagger-spec]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java项目中使用Mybatis入门程序]]></title>
      <url>%2Fpost%2Fgetting-started-mybatis%2F</url>
      <content type="text"><![CDATA[MyBatis 是支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架。 什么是 MyBatis ?MyBatis 是支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架。 MyBatis githubhttps://github.com/mybatis/mybatis-3 MyBatis 文档http://mybatis.github.io/mybatis-3/zh/index.html 入门程序想要使用 MyBatis 只需将 mybatis-x.x.x.jar 文件置于 classpath 中。如果使用 Maven 构建项目，则需将下面的 dependency 置于 pom.xml 中：12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.8.2&lt;/version&gt; &lt;/dependency&gt; 我选择第二种，在Eclipse中新建一个maven项目 项目结构： 各文件介绍： pom文件：由于使用了mySQL数据库，这里还依赖了一个mySQL驱动包 123456789101112131415161718&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;Mybatis&lt;/groupId&gt; &lt;artifactId&gt;Mybatis&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.2.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.34&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 实体类User ： 123456789101112131415161718192021222324package com.mybatis.domain; public class User &#123; private String name; private Integer age; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; &#125; UserMapper接口： 123456package com.mybatis.mapper; import com.mybatis.domain.User; public interface UserMapper &#123; public User findById(String Id); &#125; UserMapper接口的实现，userMapper.xml： 12345678&lt;?xml version="1.0" encoding="UTF-8" ?&gt; &lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt; &lt;!--相当于UserMapper接口的实现 namespace必须是UserMapper类路径--&gt;&lt;mapper namespace="com.mybatis.mapper.UserMapper"&gt; &lt;!-- findById必须和接口中的方法名一样 返回一个User--&gt; &lt;select id="findById" parameterType="String" resultType="com.mybatis.domain.User"&gt; select * from user where id=#&#123;id&#125; &lt;/select&gt; &lt;/mapper&gt; 数据源配置 configuration.xml 12345678910111213141516171819&lt;?xml version="1.0" encoding="UTF-8" ?&gt; &lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;!--数据源配置 --&gt; &lt;environments default="development"&gt; &lt;environment id="development"&gt; &lt;transactionManager type="jdbc" /&gt; &lt;dataSource type="POOLED"&gt; &lt;property name="driver" value="com.mysql.jdbc.Driver" /&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/test" /&gt; &lt;property name="username" value="root" /&gt; &lt;property name="password" value="123456" /&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;!--userMapper.xml装载进来 --&gt; &lt;mapper resource="userMapper.xml" /&gt; &lt;/mappers&gt; &lt;/configuration&gt; 测试类MyBatisTest： 12345678910111213141516171819202122232425262728293031323334package com.mybatis.test;import com.mybatis.domain.User;import com.mybatis.mapper.UserMapper;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import java.io.IOException;public class MyBatisTest &#123; /** * MyBatis SqlSessionFactory * SqlSessionFactory????SqlSession????????????SqlSession??????????commit?rollback?close???? * @return */ private static SqlSessionFactory getSessionFactory() &#123; SqlSessionFactory sessionFactory = null; String resource = "configuration.xml"; try &#123; sessionFactory = new SqlSessionFactoryBuilder().build(Resources.getResourceAsReader( resource)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return sessionFactory; &#125; public static void main(String[] args) &#123; SqlSession sqlSession = getSessionFactory().openSession(); UserMapper userMapper = sqlSession.getMapper(UserMapper.class); User user = userMapper.findById("1"); System.out.println(user.getName()); &#125;&#125; 数据库中插入条数据：id=”1” name=”wn” age=”23” 运行测试类，在控制台看到结果：wn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis初识]]></title>
      <url>%2Fpost%2Fredisinaction_readnote_01%2F</url>
      <content type="text"><![CDATA[redis是一个速度非常快的非关系数据库，他可以存储键与5种不同类型的值之间的映射，可以将储存在内存的键值对持久化到硬盘，可以使用复制特性来扩展读性能，还可以使用客户端分片来扩展读性能 reids简介redis是一个速度非常快的非关系数据库，他可以存储键与5种不同类型的值之间的映射，可以将储存在内存的键值对持久化到硬盘，可以使用复制特性来扩展读性能，还可以使用客户端分片来扩展读性能 redis与memcached的区别两者都可以用于储存键值映射，彼此的性能也相差无几，但是redis能够自动以两种方式将数据写入硬盘，并且redis除了能存储普通字符串之外，还可以储存其他4种数据结构 redis拥有两种不同形式的持久化方法他们都可以用小而紧凑的格式将储存在内存中的数据写入硬盘吗，第一种方法是时间点转储，转储既可以在”指定时间段内有指定数量的写操作执行”这一条件被满足时执行，又可以通过调用两条转储到硬盘的命令中的任何一条来执行，第二种持久化方法将所有修改了数据库的命令都写入一个只追加文件里面，用户可以根据数据的重要程度，将只追加写入设置为从不同步，每秒同步一次或者没写入一个命令就同步一次 数据结构 STRING基本命令：GET SET DEL进阶：自增 自减 LIST基本命令：RPUSH LRANGE LINDEX LPOP 进阶：从列表里面移除元素，将元素插入列表中间，将列表修剪至指定长度 SETLIST可以存储多个相同的字符串，而SET则可以通过散列来保证自己存储的每个字符串都是各部相同的 set使用无序的方式储存基本命令：SADD SMEMBER SISMEMBER SREM进阶：SINTER SUNION SDIFF HASH储存的值既可以是字符串也可以是数字值，并且用户同样可以对散列储存的数字值执行自增操作或者自减操作 散列在很多方面就想一个微缩版的redis基本命令：HSET HGET HGETALL HDEL ZSET有序集合的值被称为分值，分值必须是浮点数，有序集合是redis里面为一个既可以根据成员访问，也可以根据分值以及分值的排列顺序来访问元素的结构基本命令：ZADD ZRANGE ZRANGEBYSCORE ZREM （注：内容整理自《redis实战》）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Elasticsearch简介]]></title>
      <url>%2Fpost%2Fmastering_es_readnote_01%2F</url>
      <content type="text"><![CDATA[elasticsearch是一个可用于构建搜索应用的成品软件，区别去lucene这种中间件 Apache Lucence简介为什么elasticsearch创始人觉得使用lucene而不是自己开发全文检索库？可能是因为lucene的成熟，高性能，可扩展以及强大的功能，得到创始人的青睐，lucene有很多扩展功能，如 多语言处理，拼写检查，高亮显示等 lucene总体架构文档（document）,字段(field),词项(term)，词条(token) 倒排索引lucene将写入索引的所有信息组成一种名为倒排索引的结构，倒排索引是面向词项而不是面向文档，实际的lucene创建的索引更为复杂，也更先进，因为索引中还储存和很多其他信息，如词向量（为单个字段创建的小索引，储存改字段中所有的词条） 各字段的原始信息，文档删除标记 段（segment）每个段只会被创建一次但是会被查询多次，索引期间，段经创建就不会被修改，例如，文档被删除以后，删除信息被单独的保存在一个文件中，而段本身并没有修改 段合并多个段合并在一起，要么是强制执行，要么是有lucene的内在机制决定在某个时刻执行，段合并非常消耗I/O，且合并期间有些不再使用的信息也将被清理掉，例如:被删除的文档，不要强制执行段合并，只需要配置段合并策略，剩余的事情Lucene会自行搞定 文档数据是如果转化为倒排索引的？这个转换的过程称为分析（analysis），分析由分析器来执行，分析器由分词器(tokenizer)过滤器（filter）和字符映射器组成(character mapper),分词器用来切割词条，过滤器可以移除，修改词条流中的词条，甚至可以创造新的词条，字符映射器用于调用分词器之前的预处理操作，比如HTML文本去标签 ElasticSearch简介简介elasticsearch是一个可用于构建搜索应用的成品软件，区别去lucene这种中间件 索引es将数据储存在一个或多个索引中，就像是sql领域的数据库，es索引可能由一个或多个lucene索引构成，具体细节由es的索引分片，复制机制及其配置决定 文档是es时间中的主要实体，文档之间可能由各自不同的字段集合，且文档并没有固定的模式或强制的结构，这些规则也适用于lucene文档，事实上，es的文档最后都储存为lucene文档了 类型es每个文档都有与之对应的类型（type）定义，这允许用户在一个索引中存储多种文档类型，并为不同文档类型提供不同的映射 节点单个es服务器实例称为节点 集群多个节点来协同处理 分片es将数据散步到多个物理lucene索引上，这些索引称为分片，而散步分片的过程叫做分片处理（sharding），es会自动完成分片处理，并且让这些分片呈现出一个大索引的样子 副本为每个分片创建冗余的副本，处理查询时可以把这些副本用作最初的主分片 es架构背后的关键概念合理的默认配置，默认的分布式工作模式，对等架构可以避免单点故障，易于向集群扩充节点 es工作流程启动过程使用广播技术来发现同一个集群中的其他节点并与他们链接，集群中会有一个节点被选为管理节点，该节点复制集群的状态管理以及在集群拓扑变化时做出反应，分发索引分片到集群的相应节点上 故障检测对每一个丢失的主分片，一个新的主分片将会从原来的主分片的副本中脱颖而出，新分片和副本的放置策略是可配置的，用户可以根据具体需求进行配置 索引数据索引操作只会发生在主分片上，当把一个索引请求发送至某节点时，如果该节点没有对应的主分片或者只有副本，那么这个请求会被转发到拥有正确的主分片的节点 查询操作查询并不是一个简答的，单步骤的操作，一般来说，查询分为两个阶段，分散阶段和合并阶段 （注：内容整理自《深入理解Elasticsearch》）]]></content>
    </entry>

    
  
  
</search>
